{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdvancedDSBowl.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "11nJJUJkpHAOTWJ7ahpjXnzXPMeV59PPK",
          "timestamp": 1522764862769
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9upu9R5oBai0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "171e0409-3cc5-48d9-bf8c-e60f8348d9af",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523303560345,
          "user_tz": -180,
          "elapsed": 62298,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmpz07gjerj/pubring.gpg' created\n",
            "gpg: /tmp/tmpz07gjerj/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OouRzDzTBdMe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P__JJXAkDmxz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "deee0cc4-bb08-474d-c69a-a489ebdc19d5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523303584060,
          "user_tz": -180,
          "elapsed": 3384,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls drive/bowl/models"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "albunet32.pth\t\t    starterkit2.pth\r\n",
            "albunet.pth\t\t    starterkit_albunet.pth\r\n",
            "albustarterkit_albunet.pth  starterkit.pth\r\n",
            "starterkit2cc2mod1.pth\t    starter_starterkit_albunet.pth\r\n",
            "starterkit2cc2.pth\t    starterstarterkit_albunet.pth\r\n",
            "starterkit2cc.pth\t    unet16.pth\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "svrq85i57Dyq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir bowl/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7_OtvOqykPQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir bowl/stage1_train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LWk0P0G6Gtk4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir bowl/stage1_test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JFyqj2Kp22fj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip drive/bowl/stage1_train.zip -d bowl/stage1_train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSwAqijPGngt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip drive/bowl/stage1_test.zip -d bowl/stage1_test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h82YDIGtADv7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a8101878-9d54-4c69-9a3d-818f3a296d2e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523303636530,
          "user_tz": -180,
          "elapsed": 4903,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install telepyth"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting telepyth\n",
            "  Downloading telepyth-0.1.6.tar.gz\n",
            "Building wheels for collected packages: telepyth\n",
            "  Running setup.py bdist_wheel for telepyth ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/cc/de/cb/7b37e1991ad8586cc8e8be593c65e6bfc92c1f485442aae3bc\n",
            "Successfully built telepyth\n",
            "Installing collected packages: telepyth\n",
            "Successfully installed telepyth-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AScAAjYT4WQJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tLheHgV71FKM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm  \n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PILuYWTMQyGd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, utils\n",
        "from skimage import io, transform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SX548WFkOfXy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def precision_at(threshold, iou):\n",
        "    matches = iou > threshold\n",
        "    true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "    tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "    return tp, fp, fn\n",
        "\n",
        "def iou_t(target, pred):\n",
        "  target_y = label(target > 0.5)\n",
        "  pred_y = label(pred > 0.5)\n",
        "  true_objs = len(np.unique(target_y))\n",
        "  pred_objs = len(np.unique(pred_y))\n",
        "  intersection = np.histogram2d(target_y.flatten(),\n",
        "                                pred_y.flatten(),\n",
        "                                bins=(true_objs, pred_objs))[0]\n",
        "  \n",
        "  area_true = np.histogram(target_y, bins = true_objs)[0]\n",
        "  area_pred = np.histogram(pred_y, bins = pred_objs)[0]\n",
        "  area_true = np.expand_dims(area_true, -1)\n",
        "  area_pred = np.expand_dims(area_pred, 0)\n",
        "  \n",
        "  union = area_true + area_pred - intersection\n",
        "  \n",
        "  intersection = intersection[1:,1:]\n",
        "  union = union[1:,1:]\n",
        "  union[union == 0] = 1e-9\n",
        "\n",
        "  iou = intersection / union\n",
        "  \n",
        "  prec = []\n",
        "  for t in np.arange(0.5, 1.0, 0.05):\n",
        "    tp, fp, fn = precision_at(t, iou)\n",
        "    p = tp / (tp + fp + fn)\n",
        "    prec.append(p)\n",
        "  return np.mean(prec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PrmRN6LA4NHc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def imshow_args(x):\n",
        "    \"\"\"Matplotlib imshow arguments for plotting.\"\"\"\n",
        "    if len(x.shape)==2: return x, cm.gray\n",
        "    if x.shape[2]==1: return x[:,:,0], cm.gray\n",
        "    return x, None\n",
        "  \n",
        "def read_image(filepath, color_mode=cv2.IMREAD_COLOR, target_size=None):\n",
        "    \"\"\"Read an image from a file and resize it.\"\"\"\n",
        "    img = cv2.imread(filepath, color_mode)\n",
        "    if target_size: \n",
        "        img = cv2.resize(img, target_size, interpolation = cv2.INTER_AREA)\n",
        "    return img\n",
        "      \n",
        "def read_mask(directory, target_size=None):\n",
        "    \"\"\"Read and resize masks contained in a given directory.\"\"\"\n",
        "    for i,filename in enumerate(next(os.walk(directory))[2]):\n",
        "        mask_path = os.path.join(directory, filename)\n",
        "        mask_tmp = read_image(mask_path, cv2.IMREAD_GRAYSCALE, target_size)\n",
        "        if not i: mask = mask_tmp\n",
        "        else: mask = np.maximum(mask, mask_tmp)\n",
        "    return mask \n",
        "\n",
        "def normalize(data, type_=1): \n",
        "    \"\"\"Normalize data.\"\"\"\n",
        "    if type_==0:\n",
        "        # Convert pixel values from [0:255] to [0:1] by global factor\n",
        "        data = data.astype(np.float32) / data.max()\n",
        "    if type_==1:\n",
        "        # Convert pixel values from [0:255] to [0:1] by local factor\n",
        "        div = data.max(axis=tuple(np.arange(1,len(data.shape))), keepdims=True) \n",
        "        div[div < 0.01*data.mean()] = 1. # protect against too small pixel intensities\n",
        "        data = data.astype(np.float32)/div\n",
        "    if type_==2:\n",
        "        # Standardisation of each image \n",
        "        data = data.astype(np.float32) / data.max() \n",
        "        mean = data.mean(axis=tuple(np.arange(1,len(data.shape))), keepdims=True) \n",
        "        std = data.std(axis=tuple(np.arange(1,len(data.shape))), keepdims=True) \n",
        "        data = (data-mean)/std\n",
        "\n",
        "    return data\n",
        "  \n",
        "def invert_imgs(imgs, cutoff=.5):\n",
        "    '''Invert image if mean value is greater than cutoff.'''\n",
        "    imgs = np.array(list(map(lambda x: 1.-x if np.mean(x)<cutoff else x, imgs)))\n",
        "    return normalize(imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oTqiR_y59p1x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def process(img_rgb):\n",
        "    #green channel happends to produce slightly better results\n",
        "    #than the grayscale image and other channels\n",
        "    img_gray=img_rgb[:,:,1]#cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
        "    #morphological opening (size tuned on training data)\n",
        "    circle7=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7))\n",
        "    img_open=cv2.morphologyEx(img_gray, cv2.MORPH_OPEN, circle7)\n",
        "    #Otsu thresholding\n",
        "    img_th=cv2.threshold(img_open,0,255,cv2.THRESH_OTSU)[1]\n",
        "    #Invert the image in case the objects of interest are in the dark side\n",
        "    if(np.sum(img_th==255)>np.sum(img_th==0)):\n",
        "        img_th=cv2.bitwise_not(img_th)\n",
        "    #second morphological opening (on binary image this time)\n",
        "    bin_open=cv2.morphologyEx(img_th, cv2.MORPH_OPEN, circle7) \n",
        "    #connected components\n",
        "    cc=cv2.connectedComponents(bin_open)[1]\n",
        "    #cc=segment_on_dt(bin_open,20)\n",
        "    return cc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FMQ-ot6H0BJQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class ConvRelu(nn.Module):\n",
        "    def __init__(self, in_, out):\n",
        "        super().__init__()\n",
        "        self.conv = conv3x3(in_, out)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.activation(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G5-X2NIt0KAt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def conv3x3(in_, out):\n",
        "    return nn.Conv2d(in_, out, 3, padding=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zIpnveYrznAP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class DecoderBlockV2(nn.Module):\n",
        "    def __init__(self, in_channels, middle_channels, out_channels, is_deconv=True):\n",
        "        super(DecoderBlockV2, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        if is_deconv:\n",
        "            \"\"\"\n",
        "                Paramaters for Deconvolution were chosen to avoid artifacts, following\n",
        "                link https://distill.pub/2016/deconv-checkerboard/\n",
        "            \"\"\"\n",
        "\n",
        "            self.block = nn.Sequential(\n",
        "                ConvRelu(in_channels, middle_channels),\n",
        "                nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=4, stride=2,\n",
        "                                   padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        else:\n",
        "            self.block = nn.Sequential(\n",
        "                nn.Upsample(scale_factor=2, mode='bilinear'),\n",
        "                ConvRelu(in_channels, middle_channels),\n",
        "                ConvRelu(middle_channels, out_channels),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x4dpiKmfyaiI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class AlbuNet(nn.Module):\n",
        "    \"\"\"\n",
        "        UNet (https://arxiv.org/abs/1505.04597) with Resnet34(https://arxiv.org/abs/1512.03385) encoder\n",
        "        Proposed by Alexander Buslaev: https://www.linkedin.com/in/al-buslaev/\n",
        "        \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=1, num_filters=32, pretrained=True, is_deconv=False):\n",
        "        \"\"\"\n",
        "        :param num_classes:\n",
        "        :param num_filters:\n",
        "        :param pretrained:\n",
        "            False - no pre-trained network is used\n",
        "            True  - encoder is pre-trained with resnet34\n",
        "        :is_deconv:\n",
        "            False: bilinear interpolation is used in decoder\n",
        "            True: deconvolution is used in decoder\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.encoder = torchvision.models.resnet34(pretrained=pretrained)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv1 = nn.Sequential(self.encoder.conv1,\n",
        "                                   self.encoder.bn1,\n",
        "                                   self.encoder.relu,\n",
        "                                   self.pool)\n",
        "\n",
        "        self.conv2 = self.encoder.layer1\n",
        "\n",
        "        self.conv3 = self.encoder.layer2\n",
        "\n",
        "        self.conv4 = self.encoder.layer3\n",
        "\n",
        "        self.conv5 = self.encoder.layer4\n",
        "\n",
        "        self.center = DecoderBlockV2(512, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "\n",
        "        self.dec5 = DecoderBlockV2(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "        self.dec4 = DecoderBlockV2(256 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "        self.dec3 = DecoderBlockV2(128 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv)\n",
        "        self.dec2 = DecoderBlockV2(64 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2, is_deconv)\n",
        "        self.dec1 = DecoderBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters, is_deconv)\n",
        "        self.dec0 = ConvRelu(num_filters, num_filters)\n",
        "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(\"input size: \", x.size())\n",
        "        conv1 = self.conv1(x)\n",
        "        #print(\"conv1 size: \", conv1.size())\n",
        "        conv2 = self.conv2(conv1)\n",
        "        #print(\"conv2 size: \", conv2.size())\n",
        "        conv3 = self.conv3(conv2)\n",
        "        #print(\"conv3 size: \", conv3.size())\n",
        "        conv4 = self.conv4(conv3)\n",
        "        #print(\"conv4 size: \", conv4.size())\n",
        "        conv5 = self.conv5(conv4)\n",
        "        #print(\"conv5 size: \", conv5.size())\n",
        "\n",
        "        center = self.center(self.pool(conv5))\n",
        "        #print(\"center size: \", center.size())\n",
        "\n",
        "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
        "        #print(\"dec5 size: \", dec5.size())\n",
        "\n",
        "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
        "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
        "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
        "        dec1 = self.dec1(dec2)\n",
        "        dec0 = self.dec0(dec1)\n",
        "\n",
        "        if self.num_classes > 1:\n",
        "            x_out = self.final(dec0)\n",
        "        else:\n",
        "            x_out = self.final(dec0)\n",
        "\n",
        "        return x_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sru4SRriRW_l",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.utils.data import *\n",
        "from skimage.transform import resize\n",
        "class DSB2018Dataset(Dataset):\n",
        "    def __init__(self, root_dir, img_id, train=True, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        :param root_dir (string): Directory with all the images\n",
        "        :param img_id (list): lists of image id\n",
        "        :param train: if equals true, then read training set, so the output is image, mask and imgId\n",
        "                      if equals false, then read testing set, so the output is image and imgId\n",
        "        :param transform (callable, optional): Optional transform to be applied on a sample\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.img_id = img_id\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.images = [os.path.join(root_dir, train_id, 'images', train_id + '.png') for train_id in img_id]\n",
        "        if train:\n",
        "          self.train_masks = {train_id: [os.path.join(root_dir, train_id, 'masks', img_name) for img_name in os.listdir(os.path.join(root_dir, train_id, 'masks'))] for train_id in img_id}\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_id)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.train:\n",
        "            img_dir = os.path.join(TRAIN_DIR, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
        "            img = cv2.imread(img_dir)\n",
        "            \n",
        "            #original_h, original_w = img.shape[0], img.shape[1]\n",
        "            #img = resize(img, (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
        "            \n",
        "            #img_cc = process(img)\n",
        "            #img_cc = img_cc.reshape(img_cc.shape[0], img_cc.shape[1], 1)\n",
        "            #img = np.concatenate((img, img_cc), axis=2)\n",
        "            masks = [cv2.imread(train_mask)[..., 0] for train_mask in self.train_masks[self.img_id[idx]]]\n",
        "            mask = sum(masks)\n",
        "            #centers = []\n",
        "            #for m in masks:\n",
        "            #  centers.append(get_center(m))\n",
        "            #mask_center = sum(centers)\n",
        "            #mask_contour = get_contour(msk)\n",
        "            \n",
        "            #mask = resize(mask, (IMG_H, IMG_W), mode='constant')\n",
        "            #mask_contour = np.expand_dims(mask_contour, -1)\n",
        "            #mask_center = np.expand_dims(mask_center, -1)\n",
        "            #mask_contour = np.expand_dims(np.swapaxes(mask_contour, 2, 0), 0) / 255.0\n",
        "            #mask_center = np.expand_dims(np.swapaxes(mask_center, 2, 0), 0) / 255.0\n",
        "            mask = np.expand_dims(mask, -1)\n",
        "            mask = np.expand_dims(np.swapaxes(mask, 2, 0), 0) / 255.0\n",
        "            img = np.expand_dims(np.swapaxes(img, 2, 0), 0) / 255.0\n",
        "            sample = [torch.FloatTensor(img), torch.FloatTensor(mask)]\n",
        "          \n",
        "        else:\n",
        "            img_dir = os.path.join(self.root_dir, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
        "            img = cv2.imread(img_dir)\n",
        "            \n",
        "            original_h, original_w = img.shape[0], img.shape[1]\n",
        "            #img = resize(img, (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
        "            \n",
        "            #img_cc = process(img)\n",
        "            #img_cc = img_cc.reshape(img_cc.shape[0], img_cc.shape[1], 1)\n",
        "            #img = np.concatenate((img, img_cc), axis=2)\n",
        "            img = np.expand_dims(np.swapaxes(img, 2, 0), 0) / 255.0\n",
        "            #size = (img.shape[0],img.shape[1])  # (Height, Weidth)\n",
        "            sample = [torch.FloatTensor(img), self.img_id[idx], original_h, original_w]\n",
        "            \n",
        "        if self.transform:\n",
        "            sample =  self.transform(sample)\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PGmYDUvYO_kA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "IMG_H = 256\n",
        "IMG_W = 256\n",
        "class DSB2018Dataset_6D(Dataset):\n",
        "    def __init__(self, root_dir, img_id, train=True, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        :param root_dir (string): Directory with all the images\n",
        "        :param img_id (list): lists of image id\n",
        "        :param train: if equals true, then read training set, so the output is image, mask and imgId\n",
        "                      if equals false, then read testing set, so the output is image and imgId\n",
        "        :param transform (callable, optional): Optional transform to be applied on a sample\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.img_id = img_id\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.images = [os.path.join(root_dir, train_id, 'images', train_id + '.png') for train_id in img_id]\n",
        "        if train:\n",
        "          self.train_masks = {train_id: [os.path.join(root_dir, train_id, 'masks', img_name) for img_name in os.listdir(os.path.join(root_dir, train_id, 'masks'))] for train_id in img_id}\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_id)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.train:\n",
        "            img_dir = os.path.join(TRAIN_DIR, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
        "            img = cv2.imread(img_dir)\n",
        "            \n",
        "            #original_h, original_w = img.shape[0], img.shape[1]\n",
        "            #img = resize(img, (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
        "            \n",
        "            #img_cc = process(img)\n",
        "            #img_cc = img_cc.reshape(img_cc.shape[0], img_cc.shape[1], 1)\n",
        "            #img = np.concatenate((img, img_cc), axis=2)\n",
        "            masks = [cv2.imread(train_mask)[..., 0] for train_mask in self.train_masks[self.img_id[idx]]]\n",
        "            mask = sum(masks) #FOR STAS: Here is a mask reading and center+contour extraction\n",
        "            centers = []\n",
        "            for m in masks:\n",
        "              centers.append(get_center(m))#works only for single mask file(not for the sum of masks)\n",
        "            mask_center = sum(centers)\n",
        "            mask_contour = get_contour(mask) #works for sum of masks(but may be better for single mask file, need tests)\n",
        "            \n",
        "            #mask_center = resize(mask_center, (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
        "            #mask_contour = resize(mask_contour, (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
        "            #mask = resize(mask, (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
        "            \n",
        "            #mask = resize(mask, (IMG_H, IMG_W), mode='constant')\n",
        "            mask_contour = np.expand_dims(mask_contour, -1)\n",
        "            mask_center = np.expand_dims(mask_center, -1)\n",
        "            \n",
        "            \n",
        "            mask_contour = np.swapaxes(mask_contour, 2, 0) / 255.0\n",
        "            mask_center = np.swapaxes(mask_center, 2, 0) / 255.0\n",
        "            \n",
        "            mask = np.expand_dims(mask, -1)\n",
        "            mask = np.swapaxes(mask, 2, 0) / 255.0\n",
        "            \n",
        "            img = np.swapaxes(img, 2, 0) / 255.0\n",
        "            #print(img.shape, mask.shape, mask_center.shape, mask_contour.shape)\n",
        "            \n",
        "            \n",
        "            sample = torch.FloatTensor(np.stack((img[0], img[1], img[2], mask[0] > 0, mask_center[0] > 0, mask_contour[0] > 0)))\n",
        "            \n",
        "          \n",
        "        else:\n",
        "            img_dir = os.path.join(self.root_dir, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
        "            img = cv2.imread(img_dir)\n",
        "            \n",
        "            original_h, original_w = img.shape[0], img.shape[1]\n",
        "            img = resize(img, (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
        "            \n",
        "            #img_cc = process(img)\n",
        "            #img_cc = img_cc.reshape(img_cc.shape[0], img_cc.shape[1], 1)\n",
        "            #img = np.concatenate((img, img_cc), axis=2)\n",
        "            img = np.expand_dims(np.swapaxes(img, 2, 0), 0) / 255.0\n",
        "            #size = (img.shape[0],img.shape[1])  # (Height, Weidth)\n",
        "            sample = [torch.FloatTensor(img), self.img_id[idx], original_h, original_w]\n",
        "            \n",
        "        if self.transform:\n",
        "            sample =  self.transform(sample)\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w5froGrdkZbV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class LossBinary:\n",
        "    def __init__(self, jaccard_weight=0):\n",
        "        self.nll_loss = nn.BCEWithLogitsLoss()\n",
        "        self.jaccard_weight = jaccard_weight\n",
        "\n",
        "    def __call__(self, outputs, targets):\n",
        "        loss = self.nll_loss(outputs, targets)\n",
        "\n",
        "        if self.jaccard_weight:\n",
        "            eps = 1e-15\n",
        "            jaccard_target = (targets == 1).float()\n",
        "            jaccard_output = F.sigmoid(outputs)\n",
        "\n",
        "            intersection = (jaccard_output * jaccard_target).sum()\n",
        "            union = jaccard_output.sum() + jaccard_target.sum()\n",
        "\n",
        "            loss -= self.jaccard_weight * torch.log((intersection + eps) / (union - intersection + eps))\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_8wYL4Kb_jrP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class DanillTransform:\n",
        "    def __init__(self, trans, prob=1., instruction=(True, True, False, False)):\n",
        "        self.trans = trans\n",
        "        self.prob = prob\n",
        "        self.x_in, self.mask_in, self.center_in, self.bound_in = instruction\n",
        "\n",
        "    def __call__(self, x, mask, center, bound):\n",
        "\n",
        "        if True:\n",
        "            if self.x_in:\n",
        "                x = self.trans(x)\n",
        "            if self.mask_in:\n",
        "                mask = self.trans(mask)\n",
        "            if self.center_in:\n",
        "                center = self.trans(center)\n",
        "            if self.bound_in:\n",
        "                bound = self.trans(bound)\n",
        "        return x, mask, center, bound"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V8jnnPqp-oq6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class UnetTansformation:\n",
        "    def __init__(self, prob=.5):\n",
        "        self.prob = prob\n",
        "\n",
        "    def __call__(self, img):\n",
        "        shape = img.shape\n",
        "\n",
        "        if (shape[0] % 64 == 0) and (shape[1] % 64 == 0):\n",
        "            return img\n",
        "\n",
        "        indention_0 = 64 - shape[0] % 64\n",
        "        indention_1 = 64 - shape[1] % 64\n",
        "\n",
        "        indented_img = np.zeros((shape[0] + indention_0, shape[1] + indention_1, shape[2])).astype(np.uint8)\n",
        "        indented_img[indention_0 // 2:-(indention_0 - indention_0 // 2), indention_1 // 2:-(indention_1 - indention_1 // 2), :] = img\n",
        "        return indented_img\n",
        "\n",
        "      \n",
        "def back_shaper(img,shape:tuple):\n",
        "        if (shape[0] % 32 == 0) and (shape[1] % 32 == 0):\n",
        "            return img\n",
        "\n",
        "        indention_0 = 32 - shape[0] % 32\n",
        "        indention_1 = 32 - shape[1] % 32\n",
        "        \n",
        "        return img[indention_0 // 2:-(indention_0 - indention_0 // 2), indention_1 // 2:-(indention_1 - indention_1 // 2), :]\n",
        "      \n",
        "      \n",
        "      \n",
        "def unet_deconstructor(dataset, tensor, dirr = '../data/stage1_train/'):\n",
        "    shapes = []\n",
        "    dec_images = []\n",
        "    \n",
        "    for ids in dataset.img_id:\n",
        "        img_dir = os.path.join(dirr, ids, 'images',ids + '.png')\n",
        "        shapes.append(cv2.imread(img_dir).shape)\n",
        "        \n",
        "    for i in range(len(dataset)):\n",
        "        dec_images.append(back_shaper(tensor[i].permute(1,2,0).numpy(),shapes[i]))\n",
        "    \n",
        "    return dec_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p0dB_bcoBBgP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class DatasetV2():\n",
        "    def __init__(self, root_dir, img_id, transform=None, train=True):\n",
        "        self.root_dir = root_dir\n",
        "        self.img_id = img_id\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "        self.images = [os.path.join(root_dir, train_id, 'images', train_id + '.png') for train_id in img_id]\n",
        "        if train:\n",
        "            self.train_masks = {train_id: [os.path.join(root_dir, train_id, 'masks', img_name) for img_name in os.listdir(os.path.join(root_dir, train_id, 'masks'))] for train_id in img_id}\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if self.train:\n",
        "            img_dir = os.path.join(TRAIN_DIR, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
        "            img = cv2.imread(img_dir)\n",
        "            masks = [cv2.imread(train_mask)[..., 0] for train_mask in self.train_masks[self.img_id[idx]]]\n",
        "            mask = sum(masks) #FOR STAS: Here is a mask reading and center+contour extraction\n",
        "            centers = []\n",
        "            for m in masks:\n",
        "                centers.append(get_center(m))#works only for single mask file(not for the sum of masks)\n",
        "            mask_center = sum(centers)\n",
        "            mask_contour = get_contour(mask) #works for sum of masks(but may be better for single mask file, need tests)\n",
        "            \n",
        "            mask_contour = np.expand_dims(mask_contour, -1)\n",
        "            mask_center = np.expand_dims(mask_center, -1)\n",
        "            mask = np.expand_dims(mask, -1)\n",
        "            \n",
        "            mask[mask > 0.00001] = 255\n",
        "            #print(img.shape, mask.shape, mask_center.shape, mask_contour.shape)\n",
        "            img, mask, mask_center, mask_contour = self.transform(img, mask, mask_center, mask_contour)\n",
        "            img[:,:,0], img[:,:,2] = img[:,:,2], img[:,:,0] #return_to_RGB\n",
        "            #print(img.shape, mask.shape, mask_center.shape, mask_contour.shape)\n",
        "            \n",
        "            \n",
        "            mask = np.swapaxes(mask, 2, 0) / 255.0\n",
        "            img = np.swapaxes(img, 2, 0) / 255.0\n",
        "            mask_contour = np.swapaxes(mask_contour, 2, 0) / 255.0\n",
        "            mask_center = np.swapaxes(mask_center, 2, 0) / 255.0\n",
        "            \n",
        "            #print(img.shape, mask.shape, mask_center.shape, mask_contour.shape)\n",
        "            \n",
        "            \n",
        "            sample = torch.FloatTensor(np.stack((img[0], img[1], img[2], mask[0], mask_center[0], mask_contour[0])))\n",
        "            \n",
        "          \n",
        "        else:\n",
        "            img_dir = os.path.join(self.root_dir, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
        "            img = cv2.imread(img_dir)\n",
        "            shape = img.shape\n",
        "            print(shape)\n",
        "            img = self.transform(img)\n",
        "            img = np.swapaxes(img, 2, 0) / 255.0\n",
        "            print(img.shape)\n",
        "            sample = torch.FloatTensor(np.stack((img[0], img[1], img[2]))) # probably big crutch\n",
        "        return sample\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ADlDwVvvoA_E",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model_path = \"drive/bowl/models/\"\n",
        "submission_path = \"drive/bowl/submissions/\"\n",
        "model_name = \"albunet_resize\"\n",
        "model_file = model_name + '.pth'\n",
        "submission_file = model_name + '.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HY-KlIzA1FKT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = 'bowl/stage1_train/'\n",
        "\n",
        "train_ids = os.listdir(TRAIN_DIR)\n",
        "train_images = [os.path.join(TRAIN_DIR, train_id, 'images', train_id + '.png') \n",
        "                for train_id in train_ids]\n",
        "train_masks = {train_id: [os.path.join(TRAIN_DIR, train_id, 'masks', img_name) \n",
        "                          for img_name in os.listdir(os.path.join(TRAIN_DIR, train_id, 'masks'))]\n",
        "               for train_id in train_ids}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gKSfADLb1FK5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "TEST_DIR = 'bowl/stage1_test/'\n",
        "test_ids = os.listdir(TEST_DIR)\n",
        "test_images = [os.path.join(TEST_DIR, test_id, 'images', test_id + '.png') \n",
        "                for test_id in test_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5SLZF9VbYS3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from scipy import ndimage as ndi\n",
        "def get_contour(img):\n",
        "    img_contour = np.zeros_like(img)\n",
        "    _, contours, hierarchy = cv2.findContours(img,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "    cv2.drawContours(img_contour, contours, -1, (255, 255, 255), 2)\n",
        "    return img_contour\n",
        "  \n",
        "def get_center(img):\n",
        "    img_center = np.zeros_like(img)\n",
        "    y, x = ndi.measurements.center_of_mass(img)\n",
        "    cv2.circle(img_center, (int(x), int(y)), 4, (255, 255, 255), -1)\n",
        "    return img_center"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ESOv5InQ1FKg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "starter_model = nn.Sequential(nn.Conv2d(3, 16, (11, 11), padding=5),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Conv2d(16, 96, (5, 5), padding=2), #extra mid channels to detect more features\n",
        "                      nn.ReLU(),\n",
        "                      nn.Conv2d(96, 3, (5, 5), padding=2), #3 out channels : [0] - mask; [1] - center; [2] - border\n",
        "                      nn.Sigmoid())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "os2jLWHTP30p",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def default_loss_composition(loss1, loss2, loss3):\n",
        "  return loss1 + loss2 + loss3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cPv9G3zKAIG2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from telepyth import TelepythClient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qQhLcOKF1FKo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train(model, dataset, loss_mask, loss_center, loss_border, loss_compose_fn = default_loss_composition, best_loss_val = 9999, name_prefix=\"\", n_epochs=10, batch_size=16):\n",
        "\n",
        "  #tp = TelepythClient(token=\"3105941719605529941\")\n",
        "  #tp.send_text(\"Training on \" + name_prefix + model_name)\n",
        "  \n",
        "  N_EPOCHS = n_epochs\n",
        "  BATCH_SIZE = batch_size\n",
        "  lr = 0.0004\n",
        "  optimizer = Adam(model.parameters(), lr=lr)\n",
        "  model.cuda()\n",
        "  model.train()\n",
        "  best_loss = best_loss_val #тут храним лучший лосс среди всех эпох\n",
        "  losses = []\n",
        "  for epoch in range(N_EPOCHS): #итерируемся по числу эпох\n",
        "      report_ep = \"Epoch[{}]\".format(epoch)\n",
        "      if epoch % 10 == 9:\n",
        "        optimizer = Adam(model.parameters(), lr = lr / 5) #каждые десять эпох уменьшаем лернинг рейт(не уверен что это норм способ)\n",
        "      #tp.send_text(report_ep)\n",
        "      print(\"Epoch[{}]\".format(epoch))\n",
        "      b = 0 #храним номер текущего батча(в конце эпохи зануляется)\n",
        "      i = 0 #хз чо но пусть будет\n",
        "      avg_loss = 0 #средний лосс по эпохе\n",
        "      optimizer.zero_grad()\n",
        "      epoch_iou = [] #массив значений iou по эпохе(содержит средние значения по каждому из батчей)\n",
        "      ious = [] #массив значений iou по батчу\n",
        "      \n",
        "      for sample in dataset:\n",
        "          batch_x = Variable(sample[:3].cuda()).unsqueeze(dim=0) # получаем перве три канала(картинку), оборачиваем в вариэйбл, и расширяем до батч*каналы*высота*ширина\n",
        "\n",
        "          batch_mask = Variable(sample[3].cuda()) #читаем маску\n",
        "          \n",
        "          batch_center = Variable(sample[4].cuda()).squeeze() #читаем центры\n",
        "          \n",
        "          batch_border = Variable(sample[5].cuda()).squeeze() #читаем границы\n",
        "          \n",
        "          \n",
        "        \n",
        "          pred = model(batch_x)[0] #предиктим и берем первый элемент из батча предиктов(размер батча 1)\n",
        "          \n",
        "\n",
        "          loss_1 = loss_mask(pred[0], batch_mask) #считаем лосс по маскам\n",
        "          loss_2 = loss_center(pred[1], batch_center) #считаем лосс по центрам\n",
        "          loss_3 = loss_border(pred[2], batch_border) #считаем лосс по границам\n",
        "          loss = loss_compose_fn(loss_1, loss_2, loss_3) #композитим три лосса\n",
        "          avg_loss = 0.9 * avg_loss + 0.1 * loss.data[0] #обновляем средний лосс с учетом нового\n",
        "          loss = loss / BATCH_SIZE #хз чо но работает\n",
        "          loss.backward() #градиенты\n",
        "          iou = iou_t(batch_mask.data.cpu().numpy(), pred[0].data.cpu().numpy()) #считаем iou для конкретного изображения\n",
        "        \n",
        "          avg_loss = 0.9 * avg_loss + 0.1 * loss.data[0]#хз зачем но ещё раз обновляем средний лосс\n",
        "          losses.append(avg_loss)# добавляем в историю лоссов\n",
        "          ious.append(iou)# добавлчем список значений по батчу\n",
        "        \n",
        "          if i % BATCH_SIZE == BATCH_SIZE - 1:#если подошли к концу батча\n",
        "            \n",
        "              mean_iou = np.array(ious).mean() #считаем средний по батчу\n",
        "              epoch_iou.append(mean_iou) #добавляем в список средних по эпохе\n",
        "              ious = [] #зануляем список средних по батчу\n",
        "              \n",
        "              report_b = \"Batch #{}; Loss:{}; Mean IoU:{}\".format(b, avg_loss, mean_iou)\n",
        "              #if b % 20 == 0:\n",
        "                #tp.send_text(report_b)\n",
        "              print(report_b)\n",
        "              b += 1\n",
        "              optimizer.step() #Оптимайзим\n",
        "              i = -1\n",
        "              optimizer.zero_grad() #Зануляемся\n",
        "          i += 1\n",
        "      if (avg_loss < best_loss): #Сохраняем модель если лосс улучшился\n",
        "        iou = np.array(epoch_iou).mean()\n",
        "        best_loss = avg_loss\n",
        "        report_loss = \"Epoch loss - {}. Epoch IoU - {}. Loss improved; Model Saved as {}\".format(avg_loss, iou, model_path + name_prefix + model_file)\n",
        "        torch.save(model,  model_path + name_prefix + model_file)\n",
        "        #tp.send_text(report_loss)\n",
        "        print(report_loss)\n",
        "        \n",
        "      else: #Или не сохраняем, если не\n",
        "        report_loss = \"Epoch last loss - {}. Not an improvement\".format(avg_loss)\n",
        "        #tp.send_text(report_loss)\n",
        "        print(report_loss)\n",
        "        \n",
        "  report_end = \"Training ended\"\n",
        "  print(report_end)\n",
        "  #tp.send_text(report_end)\n",
        "  return losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cTP65SsuDSCo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def valid(model, data, loss_compose_fn = default_loss_composition, loss_mask=F.binary_cross_entropy, loss_center=F.binary_cross_entropy, loss_border=F.binary_cross_entropy):\n",
        "  model.cuda()\n",
        "  model.eval()\n",
        "  ious = []\n",
        "  losses = []\n",
        "  for sample in data:\n",
        "    x = Variable(sample[:3].cuda()).unsqueeze(dim=0)\n",
        "    y_mask = Variable(sample[3]).cuda()\n",
        "    y_center = Variable(sample[4]).cuda()\n",
        "    y_border = Variable(sample[5]).cuda()\n",
        "    \n",
        "    pred = model(x)[0]\n",
        "    \n",
        "    loss_1 = loss_mask(pred[0], y_mask)\n",
        "    loss_2 = loss_center(pred[1], y_center)\n",
        "    loss_3 = loss_border(pred[2], y_border)\n",
        "    loss = loss_compose_fn(loss_1, loss_2, loss_3)\n",
        "    \n",
        "    \n",
        "    iou = iou_t(y_mask.cpu().data.squeeze().numpy(), pred[0].data.squeeze().cpu().numpy())\n",
        "    \n",
        "    losses.append(loss.cpu().data.numpy())\n",
        "    ious.append(iou)\n",
        "    \n",
        "  val_loss = np.array(losses).mean()\n",
        "  val_iou = np.array(ious).mean()\n",
        "  \n",
        "  return val_loss, val_iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Uv-KzRmFPlz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class DanillCompose:\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, x, mask, center, bound):\n",
        "        for t in self.transforms:\n",
        "            x, mask, center, bound = t(x, mask, center, bound)\n",
        "        return x, mask, center, bound\n",
        "      \n",
        "class Reshape4:\n",
        "    def __init__(self, prob=.5):\n",
        "        self.prob = prob\n",
        "\n",
        "    def __call__(self, img, mask, center, bound):\n",
        "        shape = mask.shape\n",
        "        return img, mask.reshape(shape[0], shape[1], 1), center.reshape(shape[0], shape[1], 1), bound.reshape(shape[0],\n",
        "                                                                                                              shape[1],\n",
        "                                                                                                              1)\n",
        "\n",
        "\n",
        "train_transform = DanillCompose([\n",
        "        DanillTransform(UnetTansformation(),instruction=(True, True, True, True)),\n",
        "        #RandomCrop4(),\n",
        "        #ShiftScaleRotate4(),\n",
        "        #HorizontalFlip4(),\n",
        "        #VerticalFlip4(),\n",
        "        #DanillTransform(RandomHueSaturationValue(), instruction=(True, False, False, False)),\n",
        "        #DanillTransform(RandomBrightness(), instruction=(True, False, False, False)),\n",
        "        #DanillTransform(RandomContrast(), instruction=(True, False, False, False)),\n",
        "        #DanillTransform(Normalize(),instruction=(True, False, False, False),prob=0.5),\n",
        "        Reshape4()\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eGn56GecDdu9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset = DatasetV2(TRAIN_DIR, train_ids[:600], transform=train_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "35o2kXWZJi-A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "albunet = AlbuNet(pretrained=True, num_classes=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Nw4GLqHHk5V",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "30ab372f-95af-4760-d06c-ee0696b23f52"
      },
      "cell_type": "code",
      "source": [
        "losses = train(albunet, train_dataset, n_epochs=10, loss_mask=LossBinary(0.01), loss_center=LossBinary(0.01), loss_border=LossBinary(0.01), batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch[0]\n",
            "Batch #0; Loss:1.120306588446121; Mean IoU:0.0\n",
            "Batch #1; Loss:1.1055115564692086; Mean IoU:0.0\n",
            "Batch #2; Loss:1.117796363381246; Mean IoU:0.0\n",
            "Batch #3; Loss:1.1026031496639273; Mean IoU:0.0\n",
            "Batch #4; Loss:1.077284452947937; Mean IoU:0.004769345238095238\n",
            "Batch #5; Loss:0.9889195951501475; Mean IoU:0.0005087209302325581\n",
            "Batch #6; Loss:0.9112633032296089; Mean IoU:0.005048463540538068\n",
            "Batch #7; Loss:0.7465716314797859; Mean IoU:0.0\n",
            "Batch #8; Loss:0.9289424798966516; Mean IoU:0.0\n",
            "Batch #9; Loss:0.5228909843651698; Mean IoU:0.0\n",
            "Batch #10; Loss:0.670474293290964; Mean IoU:0.0\n",
            "Batch #11; Loss:0.6656149289361029; Mean IoU:0.0\n",
            "Batch #12; Loss:0.4982164424591738; Mean IoU:0.0\n",
            "Batch #13; Loss:0.4262549445318171; Mean IoU:0.0\n",
            "Batch #14; Loss:0.31663964758485913; Mean IoU:0.0\n",
            "Batch #15; Loss:0.4571538069696886; Mean IoU:0.0\n",
            "Batch #16; Loss:0.331546792670846; Mean IoU:0.0\n",
            "Batch #17; Loss:0.3924495575693985; Mean IoU:0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type AlbuNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type DecoderBlockV2. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type ConvRelu. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch loss - 0.3456295867140918. Epoch IoU - 0.0005736960949369925. Loss improved; Model Saved as drive/bowl/models/albunet_resize.pth\n",
            "Epoch[1]\n",
            "Batch #0; Loss:0.3914811702587918; Mean IoU:0.0\n",
            "Batch #1; Loss:0.44448894363294633; Mean IoU:0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nq29n7zeFQRn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "starter_model = torch.load(model_path + model_file)\n",
        "valid_dataset = DSB2018Dataset_5D(TRAIN_DIR, train_ids[600:])\n",
        "print(valid(starter_model, valid_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cVm27HauK06E",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "loss = np.array(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8KIxwuxlK5Jv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b26064fc-1b9a-4547-d755-02388154e308",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523038532770,
          "user_tz": -180,
          "elapsed": 925,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(loss)"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f175743c5c0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f17588ecef0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "E0npAPjIcQX8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "test_dataset = DSB2018Dataset_5D(TEST_DIR, test_ids, train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aMANDhRv1FLE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from skimage.morphology import label\n",
        "\n",
        "def rle_encoding(x):\n",
        "    dots = np.where(x.flatten() == 1)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths\n",
        "\n",
        "def prob_to_rles(x, cutoff=0.5):\n",
        "    lab_img = label(x > cutoff)\n",
        "    for i in range(1, lab_img.max() + 1):\n",
        "        yield rle_encoding(lab_img == i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MEuNrEEhcGvH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "image_ids = []\n",
        "rles = []\n",
        "#starternet.cpu()\n",
        "#albunet.cpu()\n",
        "#starternet.eval()\n",
        "#albunet.eval()\n",
        "\n",
        "for test in test_dataset:\n",
        "    #test_h = test[2]\n",
        "    #test_w = test[3]\n",
        "    \n",
        "    batch_x = test[0]\n",
        "    batch_x = Variable(batch_x).cuda()\n",
        "    \n",
        "    \n",
        "    pred_i = starter_model(batch_x)[0, 0].data.cpu().numpy()\n",
        "    \n",
        "    #pred_i = np.expand_dims(pred_i, -1)\n",
        "    #pred_i = np.swapaxes(pred_i, 0, -1)\n",
        "    #pred_i = np.squeeze(pred_i)\n",
        "    \n",
        "    for rle in prob_to_rles(pred_i):\n",
        "        image_ids.append(test[1])\n",
        "        rles.append(rle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZMNfNBCp1FLQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "submission = pd.DataFrame(data={'ImageId': image_ids,\n",
        "                                'EncodedPixels': [' '.join(map(str, x)) for x in rles]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KnbwtKngdmiA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "c395e32e-444a-41db-e3aa-e76392b49872",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523050470310,
          "user_tz": -180,
          "elapsed": 657,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "submission.head(1)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EncodedPixels</th>\n",
              "      <th>ImageId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2 28 520 33 567 24 1039 36 1083 28 1558 92 207...</td>\n",
              "      <td>eea70a7948d25a9a791dbcb39228af4ea4049fe5ebdee9...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       EncodedPixels  \\\n",
              "0  2 28 520 33 567 24 1039 36 1083 28 1558 92 207...   \n",
              "\n",
              "                                             ImageId  \n",
              "0  eea70a7948d25a9a791dbcb39228af4ea4049fe5ebdee9...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "5pC_yqBj1FLV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "submission.to_csv(submission_path + '26' + submission_file, index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZkSa5XEv1FL1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "870cfacc-4703-4aa6-8d8a-ba3d302cded8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522693526583,
          "user_tz": -180,
          "elapsed": 1644,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.csv  1.csv  bowl  data  datalab  drive  starterkit-2.csv  sub.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m_p2qbL0JOqb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!cp starterkit-2.csv drive/bowl/submissions/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aRMXLFYoJdzy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}