{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdvancedDSBowl.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "11nJJUJkpHAOTWJ7ahpjXnzXPMeV59PPK",
          "timestamp": 1522764862769
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9upu9R5oBai0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 4
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "8b5e70ed-1321-41b9-9fdc-f81feed6bd7c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522998955230,
          "user_tz": -180,
          "elapsed": 18489,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OouRzDzTBdMe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P__JJXAkDmxz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8e31fe04-c3bf-47b5-95d3-ce5d8d9d1bff",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523019645629,
          "user_tz": -180,
          "elapsed": 1693,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls drive/bowl/models"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "albunet32.pth\t\t    starterkit2.pth\r\n",
            "albunet.pth\t\t    starterkit_albunet.pth\r\n",
            "albustarterkit_albunet.pth  starterkit.pth\r\n",
            "starterkit2cc2mod1.pth\t    starter_starterkit_albunet.pth\r\n",
            "starterkit2cc2.pth\t    starterstarterkit_albunet.pth\r\n",
            "starterkit2cc.pth\t    unet16.pth\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "svrq85i57Dyq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir bowl/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7_OtvOqykPQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir bowl/stage1_train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LWk0P0G6Gtk4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir bowl/stage1_test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JFyqj2Kp22fj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip drive/bowl/stage1_train.zip -d bowl/stage1_train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSwAqijPGngt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip drive/bowl/stage1_test.zip -d bowl/stage1_test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h82YDIGtADv7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "35de0321-9ce2-4525-af4e-88ea16ea49b7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522999230796,
          "user_tz": -180,
          "elapsed": 4741,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install telepyth"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting telepyth\n",
            "  Downloading telepyth-0.1.6.tar.gz\n",
            "Building wheels for collected packages: telepyth\n",
            "  Running setup.py bdist_wheel for telepyth ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/cc/de/cb/7b37e1991ad8586cc8e8be593c65e6bfc92c1f485442aae3bc\n",
            "Successfully built telepyth\n",
            "Installing collected packages: telepyth\n",
            "Successfully installed telepyth-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AScAAjYT4WQJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tLheHgV71FKM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm  \n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PILuYWTMQyGd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, utils\n",
        "from skimage import io, transform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SX548WFkOfXy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def precision_at(threshold, iou):\n",
        "    matches = iou > threshold\n",
        "    true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "    tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "    return tp, fp, fn\n",
        "\n",
        "def iou_t(target, pred):\n",
        "  target_y = label(target > 0.5)\n",
        "  pred_y = label(pred > 0.5)\n",
        "  true_objs = len(np.unique(target_y))\n",
        "  pred_objs = len(np.unique(pred_y))\n",
        "  intersection = np.histogram2d(target_y.flatten(),\n",
        "                                pred_y.flatten(),\n",
        "                                bins=(true_objs, pred_objs))[0]\n",
        "  \n",
        "  area_true = np.histogram(target_y, bins = true_objs)[0]\n",
        "  area_pred = np.histogram(pred_y, bins = pred_objs)[0]\n",
        "  area_true = np.expand_dims(area_true, -1)\n",
        "  area_pred = np.expand_dims(area_pred, 0)\n",
        "  \n",
        "  union = area_true + area_pred - intersection\n",
        "  \n",
        "  intersection = intersection[1:,1:]\n",
        "  union = union[1:,1:]\n",
        "  union[union == 0] = 1e-9\n",
        "\n",
        "  iou = intersection / union\n",
        "  \n",
        "  prec = []\n",
        "  for t in np.arange(0.5, 1.0, 0.05):\n",
        "    tp, fp, fn = precision_at(t, iou)\n",
        "    p = tp / (tp + fp + fn)\n",
        "    prec.append(p)\n",
        "  return np.mean(prec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PrmRN6LA4NHc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def imshow_args(x):\n",
        "    \"\"\"Matplotlib imshow arguments for plotting.\"\"\"\n",
        "    if len(x.shape)==2: return x, cm.gray\n",
        "    if x.shape[2]==1: return x[:,:,0], cm.gray\n",
        "    return x, None\n",
        "  \n",
        "def read_image(filepath, color_mode=cv2.IMREAD_COLOR, target_size=None):\n",
        "    \"\"\"Read an image from a file and resize it.\"\"\"\n",
        "    img = cv2.imread(filepath, color_mode)\n",
        "    if target_size: \n",
        "        img = cv2.resize(img, target_size, interpolation = cv2.INTER_AREA)\n",
        "    return img\n",
        "      \n",
        "def read_mask(directory, target_size=None):\n",
        "    \"\"\"Read and resize masks contained in a given directory.\"\"\"\n",
        "    for i,filename in enumerate(next(os.walk(directory))[2]):\n",
        "        mask_path = os.path.join(directory, filename)\n",
        "        mask_tmp = read_image(mask_path, cv2.IMREAD_GRAYSCALE, target_size)\n",
        "        if not i: mask = mask_tmp\n",
        "        else: mask = np.maximum(mask, mask_tmp)\n",
        "    return mask \n",
        "\n",
        "def normalize(data, type_=1): \n",
        "    \"\"\"Normalize data.\"\"\"\n",
        "    if type_==0:\n",
        "        # Convert pixel values from [0:255] to [0:1] by global factor\n",
        "        data = data.astype(np.float32) / data.max()\n",
        "    if type_==1:\n",
        "        # Convert pixel values from [0:255] to [0:1] by local factor\n",
        "        div = data.max(axis=tuple(np.arange(1,len(data.shape))), keepdims=True) \n",
        "        div[div < 0.01*data.mean()] = 1. # protect against too small pixel intensities\n",
        "        data = data.astype(np.float32)/div\n",
        "    if type_==2:\n",
        "        # Standardisation of each image \n",
        "        data = data.astype(np.float32) / data.max() \n",
        "        mean = data.mean(axis=tuple(np.arange(1,len(data.shape))), keepdims=True) \n",
        "        std = data.std(axis=tuple(np.arange(1,len(data.shape))), keepdims=True) \n",
        "        data = (data-mean)/std\n",
        "\n",
        "    return data\n",
        "  \n",
        "def invert_imgs(imgs, cutoff=.5):\n",
        "    '''Invert image if mean value is greater than cutoff.'''\n",
        "    imgs = np.array(list(map(lambda x: 1.-x if np.mean(x)<cutoff else x, imgs)))\n",
        "    return normalize(imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oTqiR_y59p1x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def process(img_rgb):\n",
        "    #green channel happends to produce slightly better results\n",
        "    #than the grayscale image and other channels\n",
        "    img_gray=img_rgb[:,:,1]#cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
        "    #morphological opening (size tuned on training data)\n",
        "    circle7=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7))\n",
        "    img_open=cv2.morphologyEx(img_gray, cv2.MORPH_OPEN, circle7)\n",
        "    #Otsu thresholding\n",
        "    img_th=cv2.threshold(img_open,0,255,cv2.THRESH_OTSU)[1]\n",
        "    #Invert the image in case the objects of interest are in the dark side\n",
        "    if(np.sum(img_th==255)>np.sum(img_th==0)):\n",
        "        img_th=cv2.bitwise_not(img_th)\n",
        "    #second morphological opening (on binary image this time)\n",
        "    bin_open=cv2.morphologyEx(img_th, cv2.MORPH_OPEN, circle7) \n",
        "    #connected components\n",
        "    cc=cv2.connectedComponents(bin_open)[1]\n",
        "    #cc=segment_on_dt(bin_open,20)\n",
        "    return cc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FMQ-ot6H0BJQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class ConvRelu(nn.Module):\n",
        "    def __init__(self, in_, out):\n",
        "        super().__init__()\n",
        "        self.conv = conv3x3(in_, out)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.activation(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G5-X2NIt0KAt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def conv3x3(in_, out):\n",
        "    return nn.Conv2d(in_, out, 3, padding=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zIpnveYrznAP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class DecoderBlockV2(nn.Module):\n",
        "    def __init__(self, in_channels, middle_channels, out_channels, is_deconv=True):\n",
        "        super(DecoderBlockV2, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        if is_deconv:\n",
        "            \"\"\"\n",
        "                Paramaters for Deconvolution were chosen to avoid artifacts, following\n",
        "                link https://distill.pub/2016/deconv-checkerboard/\n",
        "            \"\"\"\n",
        "\n",
        "            self.block = nn.Sequential(\n",
        "                ConvRelu(in_channels, middle_channels),\n",
        "                nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=4, stride=2,\n",
        "                                   padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        else:\n",
        "            self.block = nn.Sequential(\n",
        "                nn.Upsample(scale_factor=2, mode='bilinear'),\n",
        "                ConvRelu(in_channels, middle_channels),\n",
        "                ConvRelu(middle_channels, out_channels),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x4dpiKmfyaiI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class AlbuNet(nn.Module):\n",
        "    \"\"\"\n",
        "        UNet (https://arxiv.org/abs/1505.04597) with Resnet34(https://arxiv.org/abs/1512.03385) encoder\n",
        "        Proposed by Alexander Buslaev: https://www.linkedin.com/in/al-buslaev/\n",
        "        \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=1, num_filters=32, pretrained=False, is_deconv=False):\n",
        "        \"\"\"\n",
        "        :param num_classes:\n",
        "        :param num_filters:\n",
        "        :param pretrained:\n",
        "            False - no pre-trained network is used\n",
        "            True  - encoder is pre-trained with resnet34\n",
        "        :is_deconv:\n",
        "            False: bilinear interpolation is used in decoder\n",
        "            True: deconvolution is used in decoder\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.encoder = torchvision.models.resnet34(pretrained=pretrained)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv1 = nn.Sequential(self.encoder.conv1,\n",
        "                                   self.encoder.bn1,\n",
        "                                   self.encoder.relu,\n",
        "                                   self.pool)\n",
        "\n",
        "        self.conv2 = self.encoder.layer1\n",
        "\n",
        "        self.conv3 = self.encoder.layer2\n",
        "\n",
        "        self.conv4 = self.encoder.layer3\n",
        "\n",
        "        self.conv5 = self.encoder.layer4\n",
        "\n",
        "        self.center = DecoderBlockV2(512, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "\n",
        "        self.dec5 = DecoderBlockV2(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "        self.dec4 = DecoderBlockV2(256 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "        self.dec3 = DecoderBlockV2(128 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv)\n",
        "        self.dec2 = DecoderBlockV2(64 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2, is_deconv)\n",
        "        self.dec1 = DecoderBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters, is_deconv)\n",
        "        self.dec0 = ConvRelu(num_filters, num_filters)\n",
        "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv1(x)\n",
        "        conv2 = self.conv2(conv1)\n",
        "        conv3 = self.conv3(conv2)\n",
        "        conv4 = self.conv4(conv3)\n",
        "        conv5 = self.conv5(conv4)\n",
        "\n",
        "        center = self.center(self.pool(conv5))\n",
        "\n",
        "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
        "\n",
        "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
        "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
        "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
        "        dec1 = self.dec1(dec2)\n",
        "        dec0 = self.dec0(dec1)\n",
        "\n",
        "        if self.num_classes > 1:\n",
        "            x_out = F.log_softmax(self.final(dec0), dim=1)\n",
        "        else:\n",
        "            x_out = self.final(dec0)\n",
        "\n",
        "        return x_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sru4SRriRW_l",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "IMG_H = 256\n",
        "IMG_W = 256\n",
        "from torch.utils.data import *\n",
        "from skimage.transform import resize\n",
        "class DSB2018Dataset(Dataset):\n",
        "    def __init__(self, root_dir, img_id, train=True, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        :param root_dir (string): Directory with all the images\n",
        "        :param img_id (list): lists of image id\n",
        "        :param train: if equals true, then read training set, so the output is image, mask and imgId\n",
        "                      if equals false, then read testing set, so the output is image and imgId\n",
        "        :param transform (callable, optional): Optional transform to be applied on a sample\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.img_id = img_id\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.images = [os.path.join(root_dir, train_id, 'images', train_id + '.png') for train_id in img_id]\n",
        "        if train:\n",
        "          self.train_masks = {train_id: [os.path.join(root_dir, train_id, 'masks', img_name) for img_name in os.listdir(os.path.join(root_dir, train_id, 'masks'))] for train_id in img_id}\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_id)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.train:\n",
        "            img_dir = os.path.join(TRAIN_DIR, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
        "            img = cv2.imread(img_dir)\n",
        "            \n",
        "            #original_h, original_w = img.shape[0], img.shape[1]\n",
        "            #img = resize(img, (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
        "            \n",
        "            #img_cc = process(img)\n",
        "            #img_cc = img_cc.reshape(img_cc.shape[0], img_cc.shape[1], 1)\n",
        "            #img = np.concatenate((img, img_cc), axis=2)\n",
        "            masks = [cv2.imread(train_mask)[..., 0] for train_mask in self.train_masks[self.img_id[idx]]]\n",
        "            mask = sum(masks)\n",
        "            #centers = []\n",
        "            #for m in masks:\n",
        "            #  centers.append(get_center(m))\n",
        "            #mask_center = sum(centers)\n",
        "            #mask_contour = get_contour(msk)\n",
        "            \n",
        "            #mask = resize(mask, (IMG_H, IMG_W), mode='constant')\n",
        "            #mask_contour = np.expand_dims(mask_contour, -1)\n",
        "            #mask_center = np.expand_dims(mask_center, -1)\n",
        "            #mask_contour = np.expand_dims(np.swapaxes(mask_contour, 2, 0), 0) / 255.0\n",
        "            #mask_center = np.expand_dims(np.swapaxes(mask_center, 2, 0), 0) / 255.0\n",
        "            mask = np.expand_dims(mask, -1)\n",
        "            mask = np.expand_dims(np.swapaxes(mask, 2, 0), 0) / 255.0\n",
        "            img = np.expand_dims(np.swapaxes(img, 2, 0), 0) / 255.0\n",
        "            sample = [torch.FloatTensor(img), torch.FloatTensor(mask)]\n",
        "          \n",
        "        else:\n",
        "            img_dir = os.path.join(self.root_dir, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
        "            img = cv2.imread(img_dir)\n",
        "            \n",
        "            original_h, original_w = img.shape[0], img.shape[1]\n",
        "            #img = resize(img, (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
        "            \n",
        "            #img_cc = process(img)\n",
        "            #img_cc = img_cc.reshape(img_cc.shape[0], img_cc.shape[1], 1)\n",
        "            #img = np.concatenate((img, img_cc), axis=2)\n",
        "            img = np.expand_dims(np.swapaxes(img, 2, 0), 0) / 255.0\n",
        "            #size = (img.shape[0],img.shape[1])  # (Height, Weidth)\n",
        "            sample = [torch.FloatTensor(img), self.img_id[idx], original_h, original_w]\n",
        "            \n",
        "        if self.transform:\n",
        "            sample =  self.transform(sample)\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PGmYDUvYO_kA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class DSB2018Dataset_6D(Dataset):\n",
        "    def __init__(self, root_dir, img_id, train=True, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        :param root_dir (string): Directory with all the images\n",
        "        :param img_id (list): lists of image id\n",
        "        :param train: if equals true, then read training set, so the output is image, mask and imgId\n",
        "                      if equals false, then read testing set, so the output is image and imgId\n",
        "        :param transform (callable, optional): Optional transform to be applied on a sample\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.img_id = img_id\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.images = [os.path.join(root_dir, train_id, 'images', train_id + '.png') for train_id in img_id]\n",
        "        if train:\n",
        "          self.train_masks = {train_id: [os.path.join(root_dir, train_id, 'masks', img_name) for img_name in os.listdir(os.path.join(root_dir, train_id, 'masks'))] for train_id in img_id}\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_id)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.train:\n",
        "            img_dir = os.path.join(TRAIN_DIR, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
        "            img = cv2.imread(img_dir)\n",
        "            \n",
        "            #original_h, original_w = img.shape[0], img.shape[1]\n",
        "            #img = resize(img, (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
        "            \n",
        "            #img_cc = process(img)\n",
        "            #img_cc = img_cc.reshape(img_cc.shape[0], img_cc.shape[1], 1)\n",
        "            #img = np.concatenate((img, img_cc), axis=2)\n",
        "            masks = [cv2.imread(train_mask)[..., 0] for train_mask in self.train_masks[self.img_id[idx]]]\n",
        "            mask = sum(masks) #FOR STAS: Here is a mask reading and center+contour extraction\n",
        "            centers = []\n",
        "            for m in masks:\n",
        "              centers.append(get_center(m))#works only for single mask file(not for the sum of masks)\n",
        "            mask_center = sum(centers)\n",
        "            mask_contour = get_contour(mask) #works for sum of masks(but may be better for single mask file, need tests)\n",
        "            \n",
        "            #mask = resize(mask, (IMG_H, IMG_W), mode='constant')\n",
        "            mask_contour = np.expand_dims(mask_contour, -1)\n",
        "            mask_center = np.expand_dims(mask_center, -1)\n",
        "            \n",
        "            mask_contour = np.swapaxes(mask_contour, 2, 0) / 255.0\n",
        "            mask_center = np.swapaxes(mask_center, 2, 0) / 255.0\n",
        "            \n",
        "            mask = np.expand_dims(mask, -1)\n",
        "            mask = np.swapaxes(mask, 2, 0) / 255.0\n",
        "            \n",
        "            img = np.swapaxes(img, 2, 0) / 255.0\n",
        "            #print(img.shape, mask.shape, mask_center.shape, mask_contour.shape)\n",
        "            \n",
        "            \n",
        "            sample = torch.FloatTensor(np.stack((img[0], img[1], img[2], mask[0], mask_center[0], mask_contour[0])))\n",
        "            \n",
        "          \n",
        "        else:\n",
        "            img_dir = os.path.join(self.root_dir, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
        "            img = cv2.imread(img_dir)\n",
        "            \n",
        "            original_h, original_w = img.shape[0], img.shape[1]\n",
        "            #img = resize(img, (IMG_H, IMG_W), mode='constant', preserve_range=True)\n",
        "            \n",
        "            #img_cc = process(img)\n",
        "            #img_cc = img_cc.reshape(img_cc.shape[0], img_cc.shape[1], 1)\n",
        "            #img = np.concatenate((img, img_cc), axis=2)\n",
        "            img = np.expand_dims(np.swapaxes(img, 2, 0), 0) / 255.0\n",
        "            #size = (img.shape[0],img.shape[1])  # (Height, Weidth)\n",
        "            sample = [torch.FloatTensor(img), self.img_id[idx], original_h, original_w]\n",
        "            \n",
        "        if self.transform:\n",
        "            sample =  self.transform(sample)\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w5froGrdkZbV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class LossBinary:\n",
        "    def __init__(self, jaccard_weight=0):\n",
        "        self.nll_loss = nn.BCEWithLogitsLoss()\n",
        "        self.jaccard_weight = jaccard_weight\n",
        "\n",
        "    def __call__(self, outputs, targets):\n",
        "        loss = self.nll_loss(outputs, targets)\n",
        "\n",
        "        if self.jaccard_weight:\n",
        "            eps = 1e-15\n",
        "            jaccard_target = (targets == 1).float()\n",
        "            jaccard_output = F.sigmoid(outputs)\n",
        "\n",
        "            intersection = (jaccard_output * jaccard_target).sum()\n",
        "            union = jaccard_output.sum() + jaccard_target.sum()\n",
        "\n",
        "            loss -= self.jaccard_weight * torch.log((intersection + eps) / (union - intersection + eps))\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ADlDwVvvoA_E",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model_path = \"drive/bowl/models/\"\n",
        "submission_path = \"drive/bowl/submissions/\"\n",
        "model_name = \"starterkit_albunet\"\n",
        "model_file = model_name + '.pth'\n",
        "submission_file = model_name + '.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HY-KlIzA1FKT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = 'bowl/stage1_train/'\n",
        "\n",
        "train_ids = os.listdir(TRAIN_DIR)\n",
        "train_images = [os.path.join(TRAIN_DIR, train_id, 'images', train_id + '.png') \n",
        "                for train_id in train_ids]\n",
        "train_masks = {train_id: [os.path.join(TRAIN_DIR, train_id, 'masks', img_name) \n",
        "                          for img_name in os.listdir(os.path.join(TRAIN_DIR, train_id, 'masks'))]\n",
        "               for train_id in train_ids}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gKSfADLb1FK5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "TEST_DIR = 'bowl/stage1_test/'\n",
        "test_ids = os.listdir(TEST_DIR)\n",
        "test_images = [os.path.join(TEST_DIR, test_id, 'images', test_id + '.png') \n",
        "                for test_id in test_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5SLZF9VbYS3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from scipy import ndimage as ndi\n",
        "def get_contour(img):\n",
        "    img_contour = np.zeros_like(img)\n",
        "    _, contours, hierarchy = cv2.findContours(img,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "    cv2.drawContours(img_contour, contours, -1, (255, 255, 255), 2)\n",
        "    return img_contour\n",
        "  \n",
        "def get_center(img):\n",
        "    img_center = np.zeros_like(img)\n",
        "    y, x = ndi.measurements.center_of_mass(img)\n",
        "    cv2.circle(img_center, (int(x), int(y)), 3, (255, 255, 255), -1)\n",
        "    return img_center"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V3DUH2Y8SfhC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "d5 = DSB2018Dataset_6D(TRAIN_DIR, train_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c_l5q-_eSxhA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mask_y = d5[0][4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ESOv5InQ1FKg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "starter_model = nn.Sequential(nn.Conv2d(3, 16, (11, 11), padding=5),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Conv2d(16, 96, (5, 5), padding=2), #extra mid channels to detect more features\n",
        "                      nn.ReLU(),\n",
        "                      nn.Conv2d(96, 3, (5, 5), padding=2), #3 out channels : [0] - mask; [1] - center; [2] - border\n",
        "                      nn.Sigmoid())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D7PUGYd2WFEA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b87dcb2e-b690-4e05-aec6-06c5f6ff745c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523025130214,
          "user_tz": -180,
          "elapsed": 621,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pred = starter_model(Variable(d5[0][:3].unsqueeze(dim=0).cuda()))\n",
        "mask_pred = pred[0][0]\n",
        "mask_pred.size()\n",
        "print(iou_t(mask_y.numpy(), mask_pred.cpu().data.numpy()))"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cPv9G3zKAIG2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from telepyth import TelepythClient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qQhLcOKF1FKo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train(model, dataset, loss_mask, loss_center, loss_border, best_loss_val = 9999, name_prefix=\"\", n_epochs=10, batch_size=16):\n",
        "  \n",
        "  tp = TelepythClient(token=\"3105941719605529941\")\n",
        "  tp.send_text(\"Training on \" + name_prefix + model_name)\n",
        "  \n",
        "  N_EPOCHS = n_epochs\n",
        "  BATCH_SIZE = batch_size\n",
        "\n",
        "  optimizer = Adam(model.parameters(), lr=0.0005)\n",
        "  model.cuda()\n",
        "  model.train()\n",
        "  best_loss = best_loss_val\n",
        "  losses = []\n",
        "  for epoch in range(N_EPOCHS):\n",
        "      report_ep = \"Epoch[{}]\".format(epoch)\n",
        "      tp.send_text(report_ep)\n",
        "      print(\"Epoch[{}]\".format(epoch))\n",
        "      b = 0\n",
        "      i = 0\n",
        "      avg_loss = 0\n",
        "      batch_num = 0\n",
        "      optimizer.zero_grad()\n",
        "      epoch_iou = []\n",
        "      ious = []\n",
        "      \n",
        "      for sample in dataset:\n",
        "          batch_x = Variable(sample[:3].cuda()).unsqueeze(dim=0)\n",
        "\n",
        "          batch_mask = Variable(sample[3].cuda())\n",
        "          \n",
        "          batch_center = Variable(sample[4].cuda()).squeeze()\n",
        "          \n",
        "          batch_border = Variable(sample[5].cuda()).squeeze()\n",
        "          \n",
        "          \n",
        "        \n",
        "          pred = model(batch_x)[0]\n",
        "          \n",
        "\n",
        "          loss_1 = loss_mask(pred[0], batch_mask)\n",
        "          loss_2 = loss_center(pred[1], batch_center)\n",
        "          loss_3 = loss_border(pred[2], batch_border)\n",
        "          loss = (loss_1 + loss_2 + loss_3)\n",
        "          avg_loss = 0.9 * avg_loss + 0.1 * loss.data[0]\n",
        "          loss = loss / BATCH_SIZE\n",
        "          loss.backward()\n",
        "          iou = iou_t(batch_mask.data.cpu().numpy(), pred[0].data.cpu().numpy())\n",
        "          #print(batch_mask.size(), pred[0].size())\n",
        "          #print(iou)\n",
        "          #z = input()\n",
        "        \n",
        "          avg_loss = 0.9 * avg_loss + 0.1 * loss.data[0]\n",
        "          losses.append(avg_loss)\n",
        "          ious.append(iou)\n",
        "        \n",
        "          if i % BATCH_SIZE == BATCH_SIZE - 1:\n",
        "            \n",
        "              mean_iou = np.array(ious).mean()\n",
        "              epoch_iou.append(mean_iou)\n",
        "              ious = []\n",
        "              \n",
        "              report_b = \"Batch #{}; Loss:{}; Mean IoU:{}\".format(b, avg_loss, mean_iou)\n",
        "              if b % 20 == 0:\n",
        "                tp.send_text(report_b)\n",
        "              print(report_b)\n",
        "              b += 1\n",
        "              optimizer.step()\n",
        "              i = -1\n",
        "              optimizer.zero_grad()\n",
        "          i += 1\n",
        "      if (avg_loss < best_loss):\n",
        "        iou = np.array(epoch_iou).mean()\n",
        "        best_loss = avg_loss\n",
        "        report_loss = \"Epoch loss - {}. Epoch IoU - {}. Loss improved; Model Saved as {}\".format(avg_loss, iou, model_path + name_prefix + model_file)\n",
        "        torch.save(model,  model_path + name_prefix + model_file)\n",
        "        tp.send_text(report_loss)\n",
        "        print(report_loss)\n",
        "        \n",
        "      else:\n",
        "        report_loss = \"Epoch last loss - {}. Not an improvement\".format(avg_loss)\n",
        "        tp.send_text(report_loss)\n",
        "        print(report_loss)\n",
        "        \n",
        "  report_end = \"Training ended\"\n",
        "  print(report_end)\n",
        "  tp.send_text(report_end)\n",
        "  return losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cTP65SsuDSCo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def valid(model, data, loss=F.binary_cross_entropy):\n",
        "  model.cuda()\n",
        "  model.eval()\n",
        "  ious = []\n",
        "  losses = []\n",
        "  for sample in data:\n",
        "    x = Variable(sample[0].cuda())\n",
        "    y = Variable(sample[1])\n",
        "    \n",
        "    predict = model(x)[:, 0]\n",
        "    predict = predict.unsqueeze(dim=0)\n",
        "    \n",
        "    loss_value = loss(predict.cpu(), y)\n",
        "    iou = iou_t(y.data.squeeze().numpy(), predict.data.squeeze().cpu().numpy())\n",
        "    losses.append(loss_value.data.numpy())\n",
        "    ious.append(iou)\n",
        "  val_loss = np.array(losses).mean()\n",
        "  val_iou = np.array(ious).mean()\n",
        "  return val_loss, val_iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R2MLbjVAQHN1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0929954e-cb24-4172-e85b-9f81bc20a834",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523023196330,
          "user_tz": -180,
          "elapsed": 617,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "len(train_ids[600:603])"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "metadata": {
        "id": "T80josZcKSo-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 8
            },
            {
              "item_id": 41
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1b1b4111-f13b-42dd-f4a3-f16a5c0ff50f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523021241022,
          "user_tz": -180,
          "elapsed": 31173,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "albu_model = AlbuNet(pretrained=True, num_filters=64, is_deconv=False)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /content/.torch/models/resnet34-333f7ec4.pth\n",
            "7.5%"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5SseH81DMxqj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eGn56GecDdu9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset = DSB2018Dataset_6D(TRAIN_DIR, train_ids[:600])\n",
        "valid_dataset = DSB2018Dataset(TRAIN_DIR, train_ids[600:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Nw4GLqHHk5V",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 53
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "ba7344eb-a14e-4857-97db-dc2b694e7c36"
      },
      "cell_type": "code",
      "source": [
        "losses = train(starter_model, train_dataset, best_loss_val=0.14880488741235703, n_epochs=90, loss_mask=F.binary_cross_entropy, loss_center=F.binary_cross_entropy, loss_border=F.binary_cross_entropy, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch[0]\n",
            "Batch #0; Loss:0.2485391799009578; Mean IoU:0.22128910469942525\n",
            "Batch #1; Loss:0.2525154665291761; Mean IoU:0.13783172055374884\n",
            "Batch #2; Loss:0.16452496716885612; Mean IoU:0.23723056785460606\n",
            "Batch #3; Loss:0.1591822787577818; Mean IoU:0.18016637932856333\n",
            "Batch #4; Loss:0.22488194073524112; Mean IoU:0.0535652548684412\n",
            "Batch #5; Loss:0.19578703690861984; Mean IoU:0.04199577407331779\n",
            "Batch #6; Loss:0.2103864502440576; Mean IoU:0.09615800395488372\n",
            "Batch #7; Loss:0.13457779660681604; Mean IoU:0.0693158346926375\n",
            "Batch #8; Loss:0.1152550642250548; Mean IoU:0.1601037090409711\n",
            "Batch #9; Loss:0.147867617683491; Mean IoU:0.15212213425292997\n",
            "Batch #10; Loss:0.18020588123954417; Mean IoU:0.24365578700390436\n",
            "Batch #11; Loss:0.18879268371240876; Mean IoU:0.23319018460978616\n",
            "Batch #12; Loss:0.15256556856683076; Mean IoU:0.1807278760540527\n",
            "Batch #13; Loss:0.24453881359970175; Mean IoU:0.21786280222744472\n",
            "Batch #14; Loss:0.19666920363524493; Mean IoU:0.25037388340997313\n",
            "Batch #15; Loss:0.2221362045287587; Mean IoU:0.1873648884922978\n",
            "Batch #16; Loss:0.25068522130891663; Mean IoU:0.17850342572127834\n",
            "Batch #17; Loss:0.22210091488383815; Mean IoU:0.2402086338965116\n",
            "Epoch last loss - 0.15042346428739833. Not an improvement\n",
            "Epoch[1]\n",
            "Batch #0; Loss:0.25950590752940395; Mean IoU:0.2015679173658575\n",
            "Batch #1; Loss:0.22151074681436972; Mean IoU:0.12294356969112624\n",
            "Batch #2; Loss:0.1669732028079635; Mean IoU:0.1738461052295075\n",
            "Batch #3; Loss:0.15790550711671414; Mean IoU:0.20202641658680404\n",
            "Batch #4; Loss:0.193425771887606; Mean IoU:0.1575347500551571\n",
            "Batch #5; Loss:0.17327302346733903; Mean IoU:0.21035586345912527\n",
            "Batch #6; Loss:0.21832786587183622; Mean IoU:0.21690504291274287\n",
            "Batch #7; Loss:0.11666215367225874; Mean IoU:0.21852420852723956\n",
            "Batch #8; Loss:0.10626044018275863; Mean IoU:0.2992342130426879\n",
            "Batch #9; Loss:0.13957060595077642; Mean IoU:0.21657370251762614\n",
            "Batch #10; Loss:0.19286319363480778; Mean IoU:0.26920066013233035\n",
            "Batch #11; Loss:0.18056046800741232; Mean IoU:0.23154257810341733\n",
            "Batch #12; Loss:0.14529206352464447; Mean IoU:0.19586867538063096\n",
            "Batch #13; Loss:0.23240108767144976; Mean IoU:0.21098547679231278\n",
            "Batch #14; Loss:0.1707942601840909; Mean IoU:0.24685941008960313\n",
            "Batch #15; Loss:0.19820935961749966; Mean IoU:0.17924024788361137\n",
            "Batch #16; Loss:0.24730525212155843; Mean IoU:0.1695373902040317\n",
            "Batch #17; Loss:0.21574112087873384; Mean IoU:0.24752612050361902\n",
            "Epoch loss - 0.14572338672266782. Epoch IoU - 0.20945957491541284. Loss improved; Model Saved as drive/bowl/models/starterkit_albunet.pth\n",
            "Epoch[2]\n",
            "Batch #0; Loss:0.24781743234538764; Mean IoU:0.21450779486456606\n",
            "Batch #1; Loss:0.20791862152085788; Mean IoU:0.1526433771843978\n",
            "Batch #2; Loss:0.15564998492125354; Mean IoU:0.2204938485205385\n",
            "Batch #3; Loss:0.1500970932823688; Mean IoU:0.24353765402397912\n",
            "Batch #4; Loss:0.17996984534770338; Mean IoU:0.24443695076739674\n",
            "Batch #5; Loss:0.16938218115367995; Mean IoU:0.2672468291615401\n",
            "Batch #6; Loss:0.22658849103524337; Mean IoU:0.23736453124766077\n",
            "Batch #7; Loss:0.11511022422718421; Mean IoU:0.2364545838715099\n",
            "Batch #8; Loss:0.1016174251569266; Mean IoU:0.3169067123522509\n",
            "Batch #9; Loss:0.1368750244977009; Mean IoU:0.22526820989512075\n",
            "Batch #10; Loss:0.1860959990846687; Mean IoU:0.27410006096908623\n",
            "Batch #11; Loss:0.17344361015738374; Mean IoU:0.23734385639674513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nq29n7zeFQRn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "c3cc7b1a-f441-4cff-ddf5-4c98d7090a63",
        "executionInfo": {
          "status": "error",
          "timestamp": 1523020865156,
          "user_tz": -180,
          "elapsed": 673,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(valid(starter_model, valid_dataset))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-7d66a66891bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarter_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmae_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn.functional' has no attribute 'mae_loss'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "E0npAPjIcQX8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "test_dataset = DSB2018Dataset(TEST_DIR, test_ids[600:], train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aMANDhRv1FLE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from skimage.morphology import label\n",
        "\n",
        "def rle_encoding(x):\n",
        "    dots = np.where(x.flatten() == 1)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths\n",
        "\n",
        "def prob_to_rles(x, cutoff=0.5):\n",
        "    lab_img = label(x > cutoff)\n",
        "    for i in range(1, lab_img.max() + 1):\n",
        "        yield rle_encoding(lab_img == i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MEuNrEEhcGvH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "image_ids = []\n",
        "rles = []\n",
        "#starternet.cpu()\n",
        "#albunet.cpu()\n",
        "#starternet.eval()\n",
        "#albunet.eval()\n",
        "\n",
        "for test in test_dataset:\n",
        "    #test_h = test[2]\n",
        "    #test_w = test[3]\n",
        "    \n",
        "    batch_x = test[0]\n",
        "    batch_x = Variable(batch_x).cuda()\n",
        "    \n",
        "    \n",
        "    pred_i = starternet(batch_x)[0, 0].data.cpu().numpy()\n",
        "    \n",
        "    #pred_i = np.expand_dims(pred_i, -1)\n",
        "    #pred_i = np.swapaxes(pred_i, 0, -1)\n",
        "    #pred_i = np.squeeze(pred_i)\n",
        "    \n",
        "    for rle in prob_to_rles(pred_i):\n",
        "        image_ids.append(test[1])\n",
        "        rles.append(rle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZMNfNBCp1FLQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "submission = pd.DataFrame(data={'ImageId': image_ids,\n",
        "                                'EncodedPixels': [' '.join(map(str, x)) for x in rles]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KnbwtKngdmiA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "df52f2f2-fefb-40e5-d9f7-6605b33b710e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523006731824,
          "user_tz": -180,
          "elapsed": 844,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "submission.head(1)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EncodedPixels</th>\n",
              "      <th>ImageId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>574 14 1267 19 1962 21 2657 23 3354 21 4054 14</td>\n",
              "      <td>ade080c6618cbbb0a25680cf847f312b5e19b22bfe1caf...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    EncodedPixels  \\\n",
              "0  574 14 1267 19 1962 21 2657 23 3354 21 4054 14   \n",
              "\n",
              "                                             ImageId  \n",
              "0  ade080c6618cbbb0a25680cf847f312b5e19b22bfe1caf...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "metadata": {
        "id": "5pC_yqBj1FLV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "submission.to_csv(submission_path + '25' + submission_file, index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZkSa5XEv1FL1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "870cfacc-4703-4aa6-8d8a-ba3d302cded8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522693526583,
          "user_tz": -180,
          "elapsed": 1644,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.csv  1.csv  bowl  data  datalab  drive  starterkit-2.csv  sub.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m_p2qbL0JOqb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!cp starterkit-2.csv drive/bowl/submissions/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aRMXLFYoJdzy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
