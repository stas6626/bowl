{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "starterkit.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9upu9R5oBai0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 4
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "da63bdc0-3159-4ad6-d679-69f18371e996",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522762613072,
          "user_tz": -180,
          "elapsed": 18093,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OouRzDzTBdMe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P__JJXAkDmxz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f9b8cc3-fd2a-4a65-a573-9e4c807ef495",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522748161025,
          "user_tz": -180,
          "elapsed": 2055,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls drive/bowl/models"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "albunet32.pth  albunet.pth  starterkit.pth  unet16.pth\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "svrq85i57Dyq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir bowl/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7_OtvOqykPQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir bowl/stage1_train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LWk0P0G6Gtk4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir bowl/stage1_test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JFyqj2Kp22fj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip drive/bowl/stage1_train.zip -d bowl/stage1_train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSwAqijPGngt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip drive/bowl/stage1_test.zip -d bowl/stage1_test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "URWZ_Wu0KG09",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "e14b9182-2114-4268-c7c0-005b7939a1fd",
        "executionInfo": {
          "status": "error",
          "timestamp": 1522762674224,
          "user_tz": -180,
          "elapsed": 2615,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def conv3x3(in_, out):\n",
        "    return nn.Conv2d(in_, out, 3, padding=1)\n",
        "\n",
        "\n",
        "class ConvRelu(nn.Module):\n",
        "    def __init__(self, in_, out):\n",
        "        super().__init__()\n",
        "        self.conv = conv3x3(in_, out)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, middle_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            ConvRelu(in_channels, middle_channels),\n",
        "            nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class UNet11(nn.Module):\n",
        "    def __init__(self, num_filters=32, pretrained=False):\n",
        "        \"\"\"\n",
        "        :param num_classes:\n",
        "        :param num_filters:\n",
        "        :param pretrained:\n",
        "            False - no pre-trained network is used\n",
        "            True  - encoder is pre-trained with VGG11\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.encoder = models.vgg11(pretrained=pretrained).features\n",
        "\n",
        "        self.relu = self.encoder[1]\n",
        "        self.conv1 = self.encoder[0]\n",
        "        self.conv2 = self.encoder[3]\n",
        "        self.conv3s = self.encoder[6]\n",
        "        self.conv3 = self.encoder[8]\n",
        "        self.conv4s = self.encoder[11]\n",
        "        self.conv4 = self.encoder[13]\n",
        "        self.conv5s = self.encoder[16]\n",
        "        self.conv5 = self.encoder[18]\n",
        "\n",
        "        self.center = DecoderBlock(num_filters * 8 * 2, num_filters * 8 * 2, num_filters * 8)\n",
        "        self.dec5 = DecoderBlock(num_filters * (16 + 8), num_filters * 8 * 2, num_filters * 8)\n",
        "        self.dec4 = DecoderBlock(num_filters * (16 + 8), num_filters * 8 * 2, num_filters * 4)\n",
        "        self.dec3 = DecoderBlock(num_filters * (8 + 4), num_filters * 4 * 2, num_filters * 2)\n",
        "        self.dec2 = DecoderBlock(num_filters * (4 + 2), num_filters * 2 * 2, num_filters)\n",
        "        self.dec1 = ConvRelu(num_filters * (2 + 1), num_filters)\n",
        "\n",
        "        self.final = nn.Conv2d(num_filters, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.relu(self.conv1(x))\n",
        "        conv2 = self.relu(self.conv2(self.pool(conv1)))\n",
        "        conv3s = self.relu(self.conv3s(self.pool(conv2)))\n",
        "        conv3 = self.relu(self.conv3(conv3s))\n",
        "        conv4s = self.relu(self.conv4s(self.pool(conv3)))\n",
        "        conv4 = self.relu(self.conv4(conv4s))\n",
        "        conv5s = self.relu(self.conv5s(self.pool(conv4)))\n",
        "        conv5 = self.relu(self.conv5(conv5s))\n",
        "\n",
        "        center = self.center(self.pool(conv5))\n",
        "\n",
        "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
        "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
        "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
        "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
        "        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n",
        "        return self.final(dec1)\n",
        "\n",
        "\n",
        "def unet11(pretrained=False, **kwargs):\n",
        "    \"\"\"\n",
        "    pretrained:\n",
        "            False - no pre-trained network is used\n",
        "            True  - encoder is pre-trained with VGG11\n",
        "            carvana - all weights are pre-trained on\n",
        "                Kaggle: Carvana dataset https://www.kaggle.com/c/carvana-image-masking-challenge\n",
        "    \"\"\"\n",
        "    model = UNet11(pretrained=pretrained, **kwargs)\n",
        "\n",
        "    if pretrained == 'carvana':\n",
        "        state = torch.load('TernausNet.pt')\n",
        "        model.load_state_dict(state['model'])\n",
        "    return model\n",
        "\n",
        "\n",
        "class DecoderBlockV2(nn.Module):\n",
        "    def __init__(self, in_channels, middle_channels, out_channels, is_deconv=True):\n",
        "        super(DecoderBlockV2, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        if is_deconv:\n",
        "            \"\"\"\n",
        "                Paramaters for Deconvolution were chosen to avoid artifacts, following\n",
        "                link https://distill.pub/2016/deconv-checkerboard/\n",
        "            \"\"\"\n",
        "\n",
        "            self.block = nn.Sequential(\n",
        "                ConvRelu(in_channels, middle_channels),\n",
        "                nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=4, stride=2,\n",
        "                                   padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        else:\n",
        "            self.block = nn.Sequential(\n",
        "                nn.Upsample(scale_factor=2, mode='bilinear'),\n",
        "                ConvRelu(in_channels, middle_channels),\n",
        "                ConvRelu(middle_channels, out_channels),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class AlbuNet(nn.Module):\n",
        "    \"\"\"\n",
        "        UNet (https://arxiv.org/abs/1505.04597) with Resnet34(https://arxiv.org/abs/1512.03385) encoder\n",
        "        Proposed by Alexander Buslaev: https://www.linkedin.com/in/al-buslaev/\n",
        "        \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=1, num_filters=32, pretrained=False, is_deconv=False):\n",
        "        \"\"\"\n",
        "        :param num_classes:\n",
        "        :param num_filters:\n",
        "        :param pretrained:\n",
        "            False - no pre-trained network is used\n",
        "            True  - encoder is pre-trained with resnet34\n",
        "        :is_deconv:\n",
        "            False: bilinear interpolation is used in decoder\n",
        "            True: deconvolution is used in decoder\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.encoder = torchvision.models.resnet34(pretrained=pretrained)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv1 = nn.Sequential(self.encoder.conv1,\n",
        "                                   self.encoder.bn1,\n",
        "                                   self.encoder.relu,\n",
        "                                   self.pool)\n",
        "\n",
        "        self.conv2 = self.encoder.layer1\n",
        "\n",
        "        self.conv3 = self.encoder.layer2\n",
        "\n",
        "        self.conv4 = self.encoder.layer3\n",
        "\n",
        "        self.conv5 = self.encoder.layer4\n",
        "\n",
        "        self.center = DecoderBlockV2(512, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "\n",
        "        self.dec5 = DecoderBlockV2(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "        self.dec4 = DecoderBlockV2(256 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "        self.dec3 = DecoderBlockV2(128 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv)\n",
        "        self.dec2 = DecoderBlockV2(64 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2, is_deconv)\n",
        "        self.dec1 = DecoderBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters, is_deconv)\n",
        "        self.dec0 = ConvRelu(num_filters, num_filters)\n",
        "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv1(x)\n",
        "        conv2 = self.conv2(conv1)\n",
        "        conv3 = self.conv3(conv2)\n",
        "        conv4 = self.conv4(conv3)\n",
        "        conv5 = self.conv5(conv4)\n",
        "\n",
        "        center = self.center(self.pool(conv5))\n",
        "\n",
        "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
        "\n",
        "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
        "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
        "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
        "        dec1 = self.dec1(dec2)\n",
        "        dec0 = self.dec0(dec1)\n",
        "\n",
        "        if self.num_classes > 1:\n",
        "            x_out = F.log_softmax(self.final(dec0), dim=1)\n",
        "        else:\n",
        "            x_out = self.final(dec0)\n",
        "\n",
        "        return x_out\n",
        "\n",
        "\n",
        "class UNet16(nn.Module):\n",
        "    def __init__(self, num_classes=1, num_filters=32, pretrained=False, is_deconv=False):\n",
        "        \"\"\"\n",
        "        :param num_classes:\n",
        "        :param num_filters:\n",
        "        :param pretrained:\n",
        "            False - no pre-trained network used\n",
        "            True - encoder pre-trained with VGG16\n",
        "        :is_deconv:\n",
        "            False: bilinear interpolation is used in decoder\n",
        "            True: deconvolution is used in decoder\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.encoder = torchvision.models.vgg16(pretrained=pretrained).features\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv1 = nn.Sequential(self.encoder[0],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[2],\n",
        "                                   self.relu)\n",
        "\n",
        "        self.conv2 = nn.Sequential(self.encoder[5],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[7],\n",
        "                                   self.relu)\n",
        "\n",
        "        self.conv3 = nn.Sequential(self.encoder[10],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[12],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[14],\n",
        "                                   self.relu)\n",
        "\n",
        "        self.conv4 = nn.Sequential(self.encoder[17],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[19],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[21],\n",
        "                                   self.relu)\n",
        "\n",
        "        self.conv5 = nn.Sequential(self.encoder[24],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[26],\n",
        "                                   self.relu,\n",
        "                                   self.encoder[28],\n",
        "                                   self.relu)\n",
        "\n",
        "        self.center = DecoderBlockV2(512, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "\n",
        "        self.dec5 = DecoderBlockV2(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "        self.dec4 = DecoderBlockV2(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
        "        self.dec3 = DecoderBlockV2(256 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv)\n",
        "        self.dec2 = DecoderBlockV2(128 + num_filters * 2, num_filters * 2 * 2, num_filters, is_deconv)\n",
        "        self.dec1 = ConvRelu(64 + num_filters, num_filters)\n",
        "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv1(x)\n",
        "        conv2 = self.conv2(self.pool(conv1))\n",
        "        conv3 = self.conv3(self.pool(conv2))\n",
        "        conv4 = self.conv4(self.pool(conv3))\n",
        "        conv5 = self.conv5(self.pool(conv4))\n",
        "\n",
        "        center = self.center(self.pool(conv5))\n",
        "\n",
        "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
        "\n",
        "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
        "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
        "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
        "        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n",
        "\n",
        "        if self.num_classes > 1:\n",
        "            x_out = F.log_softmax(self.final(dec1), dim=1)\n",
        "        else:\n",
        "            x_out = self.final(dec1)\n",
        "\n",
        "        return x_out"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ca7b550ce69f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mConvRelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SVNoCQ35Mmhu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class LossBinary:\n",
        "    \"\"\"\n",
        "    Loss defined as BCE - log(soft_jaccard)\n",
        "    Vladimir Iglovikov, Sergey Mushinskiy, Vladimir Osin,\n",
        "    Satellite Imagery Feature Detection using Deep Convolutional Neural Network: A Kaggle Competition\n",
        "    arXiv:1706.06169\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, jaccard_weight=0):\n",
        "        self.nll_loss = nn.BCEWithLogitsLoss()\n",
        "        self.jaccard_weight = jaccard_weight\n",
        "\n",
        "    def __call__(self, outputs, targets):\n",
        "        loss = self.nll_loss(outputs, targets)\n",
        "\n",
        "        if self.jaccard_weight:\n",
        "            eps = 1e-15\n",
        "            jaccard_target = (targets == 1).float()\n",
        "            jaccard_output = F.sigmoid(outputs)\n",
        "\n",
        "            intersection = (jaccard_output * jaccard_target).sum()\n",
        "            union = jaccard_output.sum() + jaccard_target.sum()\n",
        "\n",
        "            loss -= self.jaccard_weight * torch.log((intersection + eps) / (union - intersection + eps))\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_sLHEOueQXDa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class Rescale(object):\n",
        "    \"\"\"Rescale the image in a sample to a given size.\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If tuple, output is\n",
        "            matched to output_size. If int, smaller of image edges is matched\n",
        "            to output_size keeping aspect ratio the same.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size, train=True):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "        self.train = train\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        if self.train:\n",
        "            image, mask, img_id, height, width = sample['image'], sample['mask'], sample['img_id'], sample['height'],sample['width']\n",
        "\n",
        "            if isinstance(self.output_size, int):\n",
        "                new_h = new_w = self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size\n",
        "\n",
        "            new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "            # resize the image,\n",
        "            # preserve_range means not normalize the image when resize\n",
        "            img = transform.resize(image, (new_h, new_w), preserve_range=True, mode='constant')\n",
        "            mask = transform.resize(mask, (new_h, new_w), preserve_range=True, mode='constant')\n",
        "            return {'image': img, 'mask': mask, 'img_id': img_id, 'height':height, 'width':width}\n",
        "        else:\n",
        "            image, img_id, height,width = sample['image'], sample['img_id'], sample['height'],sample['width']\n",
        "            if isinstance(self.output_size, int):\n",
        "                new_h = new_w = self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size\n",
        "\n",
        "            new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "            # resize the image,\n",
        "            # preserve_range means not normalize the image when resize\n",
        "            img = transform.resize(image, (new_h, new_w), preserve_range=True, mode='constant')\n",
        "            return {'image': img, 'height': height,'width':width, 'img_id':img_id}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h82YDIGtADv7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 5
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "742a0eb3-7838-4344-b132-033ae0d2e11e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522762684613,
          "user_tz": -180,
          "elapsed": 4872,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install telepyth"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting telepyth\n",
            "  Downloading telepyth-0.1.6.tar.gz\n",
            "Building wheels for collected packages: telepyth\n",
            "  Running setup.py bdist_wheel for telepyth ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/cc/de/cb/7b37e1991ad8586cc8e8be593c65e6bfc92c1f485442aae3bc\n",
            "Successfully built telepyth\n",
            "Installing collected packages: telepyth\n",
            "Successfully installed telepyth-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AScAAjYT4WQJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tLheHgV71FKM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PILuYWTMQyGd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, utils\n",
        "from skimage import io, transform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ADlDwVvvoA_E",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model_path = \"drive/bowl/models/\"\n",
        "submission_path = \"drive/bowl/submissions/\"\n",
        "model_name = \"starterkit2\"\n",
        "model_file = model_name + '.pth'\n",
        "submission_file = model_name + '.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HY-KlIzA1FKT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = 'bowl/stage1_train/'\n",
        "\n",
        "train_ids = os.listdir(TRAIN_DIR)\n",
        "train_images = [os.path.join(TRAIN_DIR, train_id, 'images', train_id + '.png') \n",
        "                for train_id in train_ids]\n",
        "train_masks = {train_id: [os.path.join(TRAIN_DIR, train_id, 'masks', img_name) \n",
        "                          for img_name in os.listdir(os.path.join(TRAIN_DIR, train_id, 'masks'))]\n",
        "               for train_id in train_ids}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sru4SRriRW_l",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import *\n",
        "class DSB2018Dataset(Dataset):\n",
        "    def __init__(self, root_dir, img_id, train=True, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        :param root_dir (string): Directory with all the images\n",
        "        :param img_id (list): lists of image id\n",
        "        :param train: if equals true, then read training set, so the output is image, mask and imgId\n",
        "                      if equals false, then read testing set, so the output is image and imgId\n",
        "        :param transform (callable, optional): Optional transform to be applied on a sample\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.img_id = img_id\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_id)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.train:\n",
        "            img_dir = os.path.join(TRAIN_DIR, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
        "            img = cv2.imread(img_dir)\n",
        "            mask = sum((cv2.imread(train_mask)[..., 0] for train_mask in train_masks[self.img_id[idx]]))\n",
        "            mask = np.expand_dims(mask, axis=-1)\n",
        "            sample = {'image':img, 'mask':mask, 'img_id':self.img_id[idx], \"height\":img.shape[0], \"width\":img.shape[1]}\n",
        "\n",
        "        else:\n",
        "            img_dir = os.path.join(self.root_dir, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
        "            img = cv2.imread(img_dir)\n",
        "            # size = (img.shape[0],img.shape[1])  # (Height, Weidth)\n",
        "            sample = {'image': img, 'img_id': self.img_id[idx], \"height\":img.shape[0], \"width\":img.shape[1]}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQveed4nR7PC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset = DSB2018Dataset(root_dir = TRAIN_DIR, img_id = train_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ESOv5InQ1FKg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Conv2d(3, 16, (11, 11), padding=5),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Conv2d(16, 16, (5, 5), padding=2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Conv2d(16, 1, (5, 5), padding=2),\n",
        "                      nn.Sigmoid())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T80josZcKSo-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#model = AlbuNet(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZxmDAoqvPm9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = torch.load(model_path + model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cPv9G3zKAIG2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from telepyth import TelepythClient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3SKCgS5WANsG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2dc84ce-385c-48b9-f270-2237a1e5b734",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522762868693,
          "user_tz": -180,
          "elapsed": 1164,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tp = TelepythClient(token=\"3105941719605529941\")\n",
        "tp.send_text(\"Training on \" + model_name)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "qQhLcOKF1FKo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 4
            },
            {
              "item_id": 6
            },
            {
              "item_id": 7
            },
            {
              "item_id": 8
            },
            {
              "item_id": 9
            },
            {
              "item_id": 12
            },
            {
              "item_id": 14
            },
            {
              "item_id": 87
            },
            {
              "item_id": 91
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1771
        },
        "outputId": "24bfd9f4-cd41-47d1-eb1a-2fec6222b1fe"
      },
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 60\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.00025)\n",
        "model.cuda()\n",
        "model.train()\n",
        "losses = []\n",
        "for epoch in range(N_EPOCHS):\n",
        "    report_ep = \"Epoch[{}]\".format(epoch)\n",
        "    tp.send_text(report_ep)\n",
        "    print(\"Epoch[{}]\".format(epoch))\n",
        "    b = 0\n",
        "    i = 0\n",
        "    avg_loss = 0\n",
        "    batch_num = 0\n",
        "    optimizer.zero_grad()\n",
        "    for tr in train_dataset:\n",
        "        batch_x = np.expand_dims(np.swapaxes(tr['image'], 0, 2), 0) / 255.0\n",
        "        batch_x = Variable(torch.FloatTensor(batch_x).cuda())\n",
        "\n",
        "        batch_y = np.expand_dims(np.swapaxes(tr['mask'], 0, 1), 0) / 255.0\n",
        "        batch_y = Variable(torch.FloatTensor(batch_y).cuda())\n",
        "        \n",
        "        prediction = model(batch_x)[:, 0]\n",
        "\n",
        "        loss = F.binary_cross_entropy(prediction, batch_y)\n",
        "        avg_loss = 0.9 * avg_loss + 0.1 * loss.data[0]\n",
        "        loss = loss / BATCH_SIZE\n",
        "        loss.backward()\n",
        "        \n",
        "        avg_loss = 0.9 * avg_loss + 0.1 * loss.data[0]\n",
        "        losses.append(avg_loss)\n",
        "        \n",
        "        if i % BATCH_SIZE == BATCH_SIZE - 1:\n",
        "            report_b = \"Batch #{}; Loss:{}\".format(b, avg_loss)\n",
        "            if b % 10 == 0:\n",
        "              tp.send_text(report_b)\n",
        "            print(report_b)\n",
        "            b += 1\n",
        "            optimizer.step()\n",
        "            i = -1\n",
        "            optimizer.zero_grad()\n",
        "        i += 1\n",
        "    if (avg_loss < best_loss):\n",
        "      best_loss = avg_loss\n",
        "      report_loss = \"Epoch last loss - {}. Loss improved; Model Saved as {}\".format(avg_loss, model_path + model_file)\n",
        "      torch.save(model, model_path + model_file)\n",
        "      print(report_loss)\n",
        "      tp.send_text(report_loss)\n",
        "    else:\n",
        "      report_loss = \"Epoch last loss - {}. Not an improvement\".format(avg_loss)\n",
        "      print(report_loss)\n",
        "      tp.send_text(report_loss)\n",
        "\n",
        "report_end = \"Training ended\"\n",
        "print(report_end)\n",
        "tp.send_text(report_end)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch[0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([1, 360, 360, 1])) that is different to the input size (torch.Size([1, 360, 360])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([1, 256, 256, 1])) that is different to the input size (torch.Size([1, 256, 256])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([1, 696, 520, 1])) that is different to the input size (torch.Size([1, 696, 520])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([1, 320, 256, 1])) that is different to the input size (torch.Size([1, 320, 256])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([1, 640, 512, 1])) that is different to the input size (torch.Size([1, 640, 512])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch #0; Loss:0.04725679433803718\n",
            "Batch #1; Loss:0.06005329259922526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([1, 1024, 1024, 1])) that is different to the input size (torch.Size([1, 1024, 1024])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch #2; Loss:0.05391581627965605\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([1, 347, 260, 1])) that is different to the input size (torch.Size([1, 347, 260])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch #3; Loss:0.07160344311924662\n",
            "Batch #4; Loss:0.035961199565699334\n",
            "Batch #5; Loss:0.0692427763966066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([1, 1388, 1040, 1])) that is different to the input size (torch.Size([1, 1388, 1040])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([1, 1272, 603, 1])) that is different to the input size (torch.Size([1, 1272, 603])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch #6; Loss:0.0671970221678107\n",
            "Batch #7; Loss:0.07713553536835838\n",
            "Batch #8; Loss:0.07548852565348925\n",
            "Batch #9; Loss:0.06331306524828871\n",
            "Batch #10; Loss:0.037723787222312434\n",
            "Batch #11; Loss:0.061137973875245485\n",
            "Batch #12; Loss:0.07822032547175327\n",
            "Batch #13; Loss:0.0629876016028676\n",
            "Batch #14; Loss:0.05206356199156774\n",
            "Batch #15; Loss:0.048395353338870975\n",
            "Batch #16; Loss:0.0644248829344763\n",
            "Batch #17; Loss:0.07565476633729326\n",
            "Batch #18; Loss:0.04621131457397072\n",
            "Batch #19; Loss:0.03707532348157944\n",
            "Epoch last loss - 0.031192076787515. Loss improved; Model Saved as drive/bowl/models/starterkit2.pth\n",
            "Epoch[1]\n",
            "Batch #0; Loss:0.04421250492495922\n",
            "Batch #1; Loss:0.052953786480424515\n",
            "Batch #2; Loss:0.053170016636851544\n",
            "Batch #3; Loss:0.0773586235207761\n",
            "Batch #4; Loss:0.04256035637733606\n",
            "Batch #5; Loss:0.061071451598769484\n",
            "Batch #6; Loss:0.056967688178716364\n",
            "Batch #7; Loss:0.08161253896087804\n",
            "Batch #8; Loss:0.07283839300308786\n",
            "Batch #9; Loss:0.06458929262804454\n",
            "Batch #10; Loss:0.038163574745510694\n",
            "Batch #11; Loss:0.0655476822638099\n",
            "Batch #12; Loss:0.06620741511184572\n",
            "Batch #13; Loss:0.06927463041950843\n",
            "Batch #14; Loss:0.051337878604386426\n",
            "Batch #15; Loss:0.04799776419180623\n",
            "Batch #16; Loss:0.06039118375495026\n",
            "Batch #17; Loss:0.07120308129244025\n",
            "Batch #18; Loss:0.046437242882593\n",
            "Batch #19; Loss:0.03661032567677607\n",
            "Epoch last loss - 0.03306521148420663. Not an improvement\n",
            "Epoch[2]\n",
            "Batch #0; Loss:0.042053412247607815\n",
            "Batch #1; Loss:0.054581622766814164\n",
            "Batch #2; Loss:0.0533407924550076\n",
            "Batch #3; Loss:0.07069027447421655\n",
            "Batch #4; Loss:0.03706784167662727\n",
            "Batch #5; Loss:0.06332504305661778\n",
            "Batch #6; Loss:0.05765157975467123\n",
            "Batch #7; Loss:0.08023175321715767\n",
            "Batch #8; Loss:0.07281746844808888\n",
            "Batch #9; Loss:0.06849341668118591\n",
            "Batch #10; Loss:0.036084576633607965\n",
            "Batch #11; Loss:0.06089005326322083\n",
            "Batch #12; Loss:0.07034394833434675\n",
            "Batch #13; Loss:0.06428152684864778\n",
            "Batch #14; Loss:0.05217211242253888\n",
            "Batch #15; Loss:0.04757027543333041\n",
            "Batch #16; Loss:0.062365506854855896\n",
            "Batch #17; Loss:0.07413361210897843\n",
            "Batch #18; Loss:0.0461120665363394\n",
            "Batch #19; Loss:0.03643934166644423\n",
            "Epoch last loss - 0.031792124680579376. Not an improvement\n",
            "Epoch[3]\n",
            "Batch #0; Loss:0.042436452710358855\n",
            "Batch #1; Loss:0.053922666160742996\n",
            "Batch #2; Loss:0.05317461089722992\n",
            "Batch #3; Loss:0.07306239637717109\n",
            "Batch #4; Loss:0.03848026510955942\n",
            "Batch #5; Loss:0.06136134721702153\n",
            "Batch #6; Loss:0.0573057505161906\n",
            "Batch #7; Loss:0.08239509746773178\n",
            "Batch #8; Loss:0.07319750287766509\n",
            "Batch #9; Loss:0.0673004871941964\n",
            "Batch #10; Loss:0.03642545604355678\n",
            "Batch #11; Loss:0.06171255127103901\n",
            "Batch #12; Loss:0.06854584716601123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch #13; Loss:0.06507442129724011\n",
            "Batch #14; Loss:0.0520129145848961\n",
            "Batch #15; Loss:0.047422782837087195\n",
            "Batch #16; Loss:0.06232009578705585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b79iTN-Gcna8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model1 = torch.load(model_path + model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sEOwNip7E6mw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np_losses = np.array(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bgOD4TpAE9QI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "losses_frame = pd.DataFrame({\"loss\" : pd.Series(np_losses)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yfrLhodzFw2L",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e62309ac-f9f2-46e4-8be0-f273ba739666",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522747705676,
          "user_tz": -180,
          "elapsed": 2419,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir drive/bowl/losses"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘drive/bowl/losses’: No such file or directory\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8FBkGRrHFomX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "losses_frame.to_csv(\"drive/bowl/losses/\" + model_name + \".csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IY8MN1CQHdTS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "5facf178-24d4-4c4d-86c9-b193c5f1d616",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522763402235,
          "user_tz": -180,
          "elapsed": 860,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f172aea4be0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1770a003c8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gKSfADLb1FK5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "TEST_DIR = 'bowl/stage1_test/'\n",
        "test_ids = os.listdir(TEST_DIR)\n",
        "test_images = [os.path.join(TEST_DIR, test_id, 'images', test_id + '.png') \n",
        "                for test_id in test_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E0npAPjIcQX8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "test_dataset = DSB2018Dataset(TEST_DIR, test_ids, train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "28ny0CIQ6EL5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "452b54b5-8843-4fb9-e11f-139b172a4927",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522750288046,
          "user_tz": -180,
          "elapsed": 1503,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_x = np.expand_dims(np.swapaxes(test_dataset[0]['image'], 0, 2), 0) / 255.0\n",
        "batch_x = Variable(torch.FloatTensor(batch_x)).cuda()\n",
        "print(batch_x.size())\n",
        "pred = model1(batch_x)\n",
        "print(pred.size())\n",
        "pred.max()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 256, 256])\n",
            "torch.Size([1, 1, 256, 256])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Variable containing:\n",
              " 10.1626\n",
              "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "aMANDhRv1FLE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from skimage.morphology import label\n",
        "\n",
        "def rle_encoding(x):\n",
        "    dots = np.where(x.flatten() == 1)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths\n",
        "\n",
        "def prob_to_rles(x, cutoff=0.5):\n",
        "    lab_img = label(x > cutoff)\n",
        "    for i in range(1, lab_img.max() + 1):\n",
        "        yield rle_encoding(lab_img == i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MEuNrEEhcGvH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "image_ids = []\n",
        "rles = []\n",
        "model.eval()\n",
        "\n",
        "for test in test_dataset:\n",
        "    batch_x = np.expand_dims(np.swapaxes(test['image'], 0, 2), 0) / 255.0\n",
        "    batch_x = Variable(torch.FloatTensor(batch_x)).cuda()\n",
        "    \n",
        "    prediction = model1(batch_x)[0, 0].data.cpu().numpy()\n",
        "    \n",
        "    for rle in prob_to_rles(prediction):\n",
        "        image_ids.append(test['img_id'])\n",
        "        rles.append(rle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZMNfNBCp1FLQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "submission = pd.DataFrame(data={'ImageId': image_ids,\n",
        "                                'EncodedPixels': [' '.join(map(str, x)) for x in rles]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KnbwtKngdmiA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "b4e5b8a1-c605-45c5-cd06-1f41a172ba58",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522763567688,
          "user_tz": -180,
          "elapsed": 608,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "submission.head(1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EncodedPixels</th>\n",
              "      <th>ImageId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1 36 513 8 527 22 1025 7 1037 25 1537 7 1549 2...</td>\n",
              "      <td>17b9bf4356db24967c4677b8376ac38f826de73a88b93a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       EncodedPixels  \\\n",
              "0  1 36 513 8 527 22 1025 7 1037 25 1537 7 1549 2...   \n",
              "\n",
              "                                             ImageId  \n",
              "0  17b9bf4356db24967c4677b8376ac38f826de73a88b93a...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "5pC_yqBj1FLV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "submission.to_csv(submission_path + submission_file, index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZkSa5XEv1FL1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "870cfacc-4703-4aa6-8d8a-ba3d302cded8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522693526583,
          "user_tz": -180,
          "elapsed": 1644,
          "user": {
            "displayName": "Даниил Ларионов",
            "photoUrl": "//lh3.googleusercontent.com/-ctIQBLRHGYI/AAAAAAAAAAI/AAAAAAAAABg/_SlKdw9EHys/s50-c-k-no/photo.jpg",
            "userId": "100808819455405962260"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.csv  1.csv  bowl  data  datalab  drive  starterkit-2.csv  sub.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m_p2qbL0JOqb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!cp starterkit-2.csv drive/bowl/submissions/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aRMXLFYoJdzy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}