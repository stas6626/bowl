{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import ndimage as ndi\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "import torch as t\n",
    "from torch.nn.modules.loss import BCELoss, BCEWithLogitsLoss\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as tsf\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from torchvision import models\n",
    "from transforms import *\n",
    "from models import *\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from utils_and_losses import *\n",
    "torch.manual_seed(1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN_PATH = './train.pth'\n",
    "TEST_PATH = './test.tph'\n",
    "%matplotlib inline\n",
    "files_for_test = sorted(list(Path('../data/stage_1_test/').iterdir()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def process(file_path, has_mask=True):\n",
    "    file_path = Path(file_path)\n",
    "    files = sorted(list(Path(file_path).iterdir()))\n",
    "    datas = []\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        \n",
    "        item = {}\n",
    "        imgs = []\n",
    "        for image in (file/'images').iterdir():\n",
    "            img = io.imread(image)\n",
    "            imgs.append(img)\n",
    "        #assert len(imgs)==1\n",
    "        if img.shape[2]>3:\n",
    "            omg = file\n",
    "            #assert(img[:,:,3]!=255).sum()==0\n",
    "        img = img[:,:,:3]\n",
    "\n",
    "        if has_mask:\n",
    "            mask_files = list((file/'masks').iterdir())\n",
    "            masks = None\n",
    "            for ii,mask in enumerate(mask_files):\n",
    "                mask = io.imread(mask)\n",
    "                omg = file\n",
    "                #assert (mask[(mask!=0)]==255).all()\n",
    "                if masks is None:\n",
    "                    H,W = mask.shape\n",
    "                    masks = np.zeros((len(mask_files),H,W))\n",
    "                masks[ii] = mask\n",
    "            tmp_mask = masks.sum(0)\n",
    "            omg = file\n",
    "            #assert (tmp_mask[tmp_mask!=0] == 255).all()\n",
    "            for ii,mask in enumerate(masks):\n",
    "                masks[ii] = mask/255 * (ii+1)\n",
    "            mask = masks.sum(0)\n",
    "            item['mask'] = t.from_numpy(mask)\n",
    "        item['name'] = str(file).split('/')[-1]\n",
    "        item['img'] = t.from_numpy(img)\n",
    "        datas.append(item)\n",
    "    return datas\n",
    "\n",
    "train_data = process('../data/stage1_train/')\n",
    "t.save(train_data, TRAIN_PATH)\n",
    "test = process('../data/stage_1_test/',False)\n",
    "t.save(test, TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "    tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "    return tp, fp, fn\n",
    "\n",
    "def read_image(filepath, color_mode=cv2.IMREAD_COLOR, target_size=None):\n",
    "    \"\"\"Read an image from a file and resize it.\"\"\"\n",
    "    img = cv2.imread(filepath, color_mode)\n",
    "    if target_size: \n",
    "        img = cv2.resize(img, target_size, interpolation = cv2.INTER_AREA)\n",
    "    return img\n",
    "      \n",
    "def read_mask(directory, target_size=None):\n",
    "    \"\"\"Read and resize masks contained in a given directory.\"\"\"\n",
    "    for i,filename in enumerate(next(os.walk(directory))[2]):\n",
    "        mask_path = os.path.join(directory, filename)\n",
    "        mask_tmp = read_image(mask_path, cv2.IMREAD_GRAYSCALE, target_size)\n",
    "        if not i: mask = mask_tmp\n",
    "        else: mask = np.maximum(mask, mask_tmp)\n",
    "    return mask \n",
    "\n",
    "def get_contour(img):\n",
    "    img_contour = np.zeros_like(img)\n",
    "    _, contours, hierarchy = cv2.findContours(img,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    cv2.drawContours(img_contour, contours, -1, (255, 255, 255), 2)\n",
    "    return img_contour\n",
    "\n",
    "def iou_t(target, pred):\n",
    "    target_y = label(target > 0.5)\n",
    "    pred_y = label(pred > 0.5)\n",
    "    true_objs = len(np.unique(target_y))\n",
    "    pred_objs = len(np.unique(pred_y))\n",
    "    intersection = np.histogram2d(target_y.flatten(),\n",
    "                                pred_y.flatten(),\n",
    "                                bins=(true_objs, pred_objs))[0]\n",
    "  \n",
    "    area_true = np.histogram(target_y, bins = true_objs)[0]\n",
    "    area_pred = np.histogram(pred_y, bins = pred_objs)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "  \n",
    "    union = area_true + area_pred - intersection\n",
    "  \n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    iou = intersection / union\n",
    "  \n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        p = tp / (tp + fp + fn)\n",
    "        prec.append(p)\n",
    "    return np.mean(prec)\n",
    "  \n",
    "def get_center(img):\n",
    "    img_center = np.zeros_like(img)\n",
    "    y, x = ndi.measurements.center_of_mass(img)\n",
    "    cv2.circle(img_center, (int(x), int(y)), 3, (255, 255, 255), -1)\n",
    "    return img_center\n",
    "\n",
    "TRAIN_DIR = '../data/stage1_train/'\n",
    "\n",
    "train_ids = os.listdir(TRAIN_DIR)\n",
    "train_images = [os.path.join(TRAIN_DIR, train_id, 'images', train_id + '.png') \n",
    "                for train_id in train_ids]\n",
    "train_masks = {train_id: [os.path.join(TRAIN_DIR, train_id, 'masks', img_name) \n",
    "                          for img_name in os.listdir(os.path.join(TRAIN_DIR, train_id, 'masks'))]\n",
    "               for train_id in train_ids}\n",
    "\n",
    "TEST_DIR = '../data/stage_1_test/'\n",
    "test_ids = os.listdir(TEST_DIR)\n",
    "test_images = [os.path.join(TEST_DIR, test_id, 'images', test_id + '.png') \n",
    "                for test_id in test_ids]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_data = t.load(TRAIN_PATH)\n",
    "test = t.load(TEST_PATH)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "bad = []\n",
    "\n",
    "img_dir = os.path.join(TRAIN_DIR,train_ids[0], 'images',train_ids[0] + '.png')\n",
    "img = cv2.imread(img_dir)\n",
    "\n",
    "for i, ids in enumerate(train_ids):\n",
    "    img_dir = os.path.join(TRAIN_DIR,ids, 'images',ids + '.png')\n",
    "    if cv2.imread(img_dir).shape[0]%32 != 0 or cv2.imread(img_dir).shape[1]%32 != 0:\n",
    "        bad.append((i, cv2.imread(img_dir).shape))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, root_dir, img_id, transform=None, train=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.img_id = img_id\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.images = [os.path.join(root_dir, train_id, 'images', train_id + '.png') for train_id in img_id]\n",
    "        if train:\n",
    "            self.train_masks = {train_id: [os.path.join(root_dir, train_id, 'masks', img_name) for img_name in os.listdir(os.path.join(root_dir, train_id, 'masks'))] for train_id in img_id}\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            img_dir = os.path.join(TRAIN_DIR, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
    "            img = cv2.imread(img_dir)\n",
    "            masks = [cv2.imread(train_mask)[..., 0] for train_mask in self.train_masks[self.img_id[idx]]]\n",
    "            mask = sum(masks) #FOR STAS: Here is a mask reading and center+contour extraction\n",
    "            centers = []\n",
    "            for m in masks:\n",
    "                centers.append(get_center(m))#works only for single mask file(not for the sum of masks)\n",
    "            mask_center = sum(centers)\n",
    "            mask_contour = get_contour(mask) #works for sum of masks(but may be better for single mask file, need tests)\n",
    "            \n",
    "            mask_contour = np.expand_dims(mask_contour, -1)\n",
    "            mask_center = np.expand_dims(mask_center, -1)\n",
    "            mask = np.expand_dims(mask, -1)\n",
    "            \n",
    "            mask[mask > 0.00001] = 255\n",
    "            # print(img.shape, mask.shape, mask_center.shape, mask_contour.shape)\n",
    "            img, mask, mask_center, mask_contour = self.transform(img, mask, mask_center, mask_contour)\n",
    "            img[:,:,0], img[:,:,2] = img[:,:,2], img[:,:,0] #return_to_RGB\n",
    "            # print(img.shape, mask.shape, mask_center.shape, mask_contour.shape)\n",
    "            \n",
    "            \n",
    "            mask = np.swapaxes(mask, 2, 0) / 255.0\n",
    "            img = np.swapaxes(img, 2, 0) / 255.0\n",
    "            mask_contour = np.swapaxes(mask_contour, 2, 0) / 255.0\n",
    "            mask_center = np.swapaxes(mask_center, 2, 0) / 255.0\n",
    "            \n",
    "            # print(img.shape, mask.shape, mask_center.shape, mask_contour.shape)\n",
    "            \n",
    "            \n",
    "            # sample = torch.FloatTensor(np.stack((img[0], img[1], img[2], mask[0], mask_center[0], mask_contour[0])))\n",
    "            return torch.FloatTensor(np.stack((img[0], img[1], img[2]))) , torch.FloatTensor(np.stack((mask[0], mask_center[0], mask_contour[0])))\n",
    "            \n",
    "          \n",
    "        else:\n",
    "            img_dir = os.path.join(self.root_dir, self.img_id[idx], 'images', self.img_id[idx] + '.png')\n",
    "            img = cv2.imread(img_dir)\n",
    "            shape = img.shape\n",
    "            # print(shape)\n",
    "            img = self.transform(img)\n",
    "            img[:,:,0], img[:,:,2] = img[:,:,2], img[:,:,0] #return_to_RGB\n",
    "            img = np.swapaxes(img, 2, 0) / 255.0\n",
    "            # print(img.shape)\n",
    "            # sample = torch.FloatTensor(np.stack((img[0], img[1], img[2]))) # probably big crutch\n",
    "            return torch.FloatTensor(np.stack((img[0], img[1], img[2])))\n",
    "        # return sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = DanillCompose([\n",
    "        DanillTransform(UnetTansformation(),instruction=(True, True, True, True)),\n",
    "        RandomCrop4(prob=0),\n",
    "        ShiftScaleRotate4(),\n",
    "        HorizontalFlip4(),\n",
    "        VerticalFlip4(),\n",
    "        DanillTransform(RandomHueSaturationValue(), instruction=(True, False, False, False)),\n",
    "        DanillTransform(RandomBrightness(limit=0.1), instruction=(True, False, False, False)),\n",
    "        DanillTransform(RandomContrast(limit=0.1), instruction=(True, False, False, False)),\n",
    "        DanillTransform(Normalize(),instruction=(True, False, False, False),prob=0.5),\n",
    "        Reshape4()\n",
    "    ])\n",
    "\n",
    "val_transform = DanillCompose([\n",
    "    DanillTransform(UnetTansformation(),instruction=(True, True, True, True)),\n",
    "    RandomCrop4(prob=0),\n",
    "    DanillTransform(RandomHueSaturationValue(), instruction=(True, False, False, False)),\n",
    "    DanillTransform(RandomBrightness(limit=0.1), instruction=(True, False, False, False)),\n",
    "    DanillTransform(RandomContrast(limit=0.1), instruction=(True, False, False, False)),\n",
    "    DanillTransform(Normalize(),instruction=(True, False, False, False),prob=0.5),\n",
    "    Reshape4()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/stas/fastdata/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "training_ids, valid_ids = train_test_split(train_ids, shuffle = True, train_size=0.8)\n",
    "\n",
    "train_dataset = Dataset(TRAIN_DIR, training_ids, transform=train_transform)\n",
    "valid_dataset = Dataset(TRAIN_DIR, valid_ids   , transform=val_transform)\n",
    "\n",
    "trainloader = t.utils.data.DataLoader(train_dataset, batch_size = 16, shuffle = True, num_workers = 16)\n",
    "validloader = t.utils.data.DataLoader(valid_dataset, batch_size = 100, shuffle = True, num_workers = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 114 ms, sys: 4.13 ms, total: 118 ms\n",
      "Wall time: 117 ms\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f37d107c390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "x, y = valid_dataset[32]\n",
    "img, mask, mask_center, mask_contour = x[[0,1,2]].permute(1,2,0).numpy(), y[0].numpy(), y[1].numpy(), y[2].numpy()\n",
    "\n",
    "if img.min() < 0:\n",
    "    img = img * .5 + .5\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(img)\n",
    "plt.subplot(222)\n",
    "plt.imshow(mask)\n",
    "plt.subplot(223)\n",
    "plt.imshow(mask_center)\n",
    "plt.subplot(224)\n",
    "plt.imshow(mask_contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1518244421288/work/torch/lib/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a5709d9f5ff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlbuNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLossBinary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;31m# Variables stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1518244421288/work/torch/lib/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "model = AlbuNet(pretrained=True, num_classes=3).cuda()\n",
    "optimizer = t.optim.Adam(model.parameters(),lr = 5e-5)\n",
    "loss_bin = LossBinary(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array = []\n",
    "minimalochka = 100\n",
    "early_stop = 10\n",
    "i_will_wait = 0\n",
    "ious = []\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    model.train()\n",
    "    for x_train, y_train  in trainloader:\n",
    "        ls = []\n",
    "        #print(sample.shape)\n",
    "        x = t.autograd.Variable(x_train.cuda())\n",
    "        y = t.autograd.Variable(y_train.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        o = model(x)\n",
    "        loss = loss_bin(o, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ls.append(loss.data[0])\n",
    "    \n",
    "    loss_array.append(np.mean(ls))\n",
    "    model.eval()\n",
    "    iou = []\n",
    "    for x_train, y_train  in validloader:#valid\n",
    "        ls = []\n",
    "        x = t.autograd.Variable(x_train.cuda())\n",
    "        y = t.autograd.Variable(y_train.cuda())\n",
    "        \n",
    "        o = model(x)\n",
    "        \n",
    "        for i in range(len(o)):\n",
    "            iou.append(iou_t(y[i][0].data.cpu().numpy(), o[i][0].data.cpu().numpy()))\n",
    "            \n",
    "    ious.append(np.mean(iou))\n",
    "    \n",
    "    \n",
    "    if loss_array[-1] < minimalochka:\n",
    "        minimalochka = loss_array[-1]\n",
    "        i_will_wait = 0\n",
    "        #print(epoch + 1,loss_array[-1],end=\"\")\n",
    "        torch.save(model, \"cool_model.torch\")\n",
    "    if i_will_wait > (early_stop-1):\n",
    "        print(epoch + 1)\n",
    "        break\n",
    "        \n",
    "    i_will_wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [03:20<09:02,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "CPU times: user 2min 42s, sys: 40.1 s, total: 3min 22s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in tqdm(range(100)):\n",
    "    model.train()\n",
    "    \n",
    "    for x_train, y_train  in trainloader:#train\n",
    "        ls = []\n",
    "        x_train = t.autograd.Variable(x_train).cuda()\n",
    "        y_train = t.autograd.Variable(y_train).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        o = model(x_train)\n",
    "        loss = LossBinary()      \n",
    "        output = loss(o, y_train)\n",
    "        \n",
    "        output.backward()\n",
    "        optimizer.step()\n",
    "        iou = iou_t(batch_mask.data.cpu().numpy(), pred[0].data.cpu().numpy())\n",
    "        ls.append(output.data[0])\n",
    "        \n",
    "    #model.eval()\n",
    "    \"\"\"for x_train, y_train  in validloader:#valid\n",
    "        ls = []\n",
    "        x_train = t.autograd.Variable(x_train).cuda()\n",
    "        y_train = t.autograd.Variable(y_train).cuda()\n",
    "        \n",
    "        o = model(x_train)\n",
    "        loss = LossBinary()      \n",
    "        output = loss(o, y_train)\n",
    "        ls.append(output.data[0])\n",
    "        \n",
    "    loss_array.append(np.mean(ls))\n",
    "\"\"\"\n",
    "    loss_array.append(np.mean(ls))\n",
    "    if loss_array[-1] < minimalochka:\n",
    "        minimalochka = loss_array[-1]\n",
    "        i_will_wait = 0\n",
    "        #print(epoch + 1,loss_array[-1],end=\"\")\n",
    "        torch.save(model, \"cool_model.torch\")\n",
    "    if i_will_wait > (early_stop-1):\n",
    "        print(epoch + 1)\n",
    "        break\n",
    "        \n",
    "    i_will_wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_loss_composition(loss1, loss2, loss3):\n",
    "    return loss1 + loss2 + loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, loss_mask, loss_center, loss_border, loss_compose_fn = default_loss_composition, best_loss_val = 9999, name_prefix=\"\", n_epochs=10, batch_size=16):\n",
    "    N_EPOCHS = n_epochs\n",
    "    BATCH_SIZE = batch_size\n",
    "    lr = 0.0004\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    best_loss = best_loss_val #тут храним лучший лосс среди всех эпох\n",
    "    losses = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(N_EPOCHS): #итерируемся по числу эпох\n",
    "        if epoch % 10 == 9:\n",
    "            optimizer = Adam(model.parameters(), lr = lr / 5) #каждые десять эпох уменьшаем лернинг рейт(не уверен что это норм способ)\n",
    "        print(f\"Epoch[{epoch}]\")\n",
    "        b = 0 #храним номер текущего батча(в конце эпохи зануляется)\n",
    "        i = 0 #хз чо но пусть будет\n",
    "        avg_loss = 0 #средний лосс по эпохе\n",
    "        optimizer.zero_grad()\n",
    "        epoch_iou = [] #массив значений iou по эпохе(содержит средние значения по каждому из батчей)\n",
    "        ious = [] #массив значений iou по батчу\n",
    "\n",
    "        for sample in dataset:\n",
    "            batch_x = Variable(sample[:3].cuda()).unsqueeze(dim=0) # получаем перве три канала(картинку), оборачиваем в вариэйбл, и расширяем до батч*каналы*высота*ширина\n",
    "\n",
    "            batch_mask = Variable(sample[3].cuda()) #читаем маску\n",
    "\n",
    "            batch_center = Variable(sample[4].cuda()).squeeze() #читаем центры\n",
    "\n",
    "            batch_border = Variable(sample[5].cuda()).squeeze() #читаем границы\n",
    "\n",
    "\n",
    "\n",
    "            pred = model(batch_x)[0] #предиктим и берем первый элемент из батча предиктов(размер батча 1)\n",
    "\n",
    "\n",
    "            loss_1 = loss_mask(pred[0], batch_mask) #считаем лосс по маскам\n",
    "            loss_2 = loss_center(pred[1], batch_center) #считаем лосс по центрам\n",
    "            loss_3 = loss_border(pred[2], batch_border) #считаем лосс по границам\n",
    "            loss = loss_compose_fn(loss_1, loss_2, loss_3) #композитим три лосса\n",
    "            avg_loss = 0.9 * avg_loss + 0.1 * loss.data[0] #обновляем средний лосс с учетом нового\n",
    "            loss = loss / BATCH_SIZE #хз чо но работает\n",
    "            loss.backward() #градиенты\n",
    "            iou = iou_t(batch_mask.data.cpu().numpy(), pred[0].data.cpu().numpy()) #считаем iou для конкретного изображения\n",
    "\n",
    "            avg_loss = 0.9 * avg_loss + 0.1 * loss.data[0]#хз зачем но ещё раз обновляем средний лосс\n",
    "            losses.append(avg_loss)# добавляем в историю лоссов\n",
    "            ious.append(iou)# добавлчем список значений по батчу\n",
    "        \n",
    "            if i % BATCH_SIZE == BATCH_SIZE - 1:#если подошли к концу батча\n",
    "            \n",
    "                mean_iou = np.array(ious).mean() #считаем средний по батчу\n",
    "                epoch_iou.append(mean_iou) #добавляем в список средних по эпохе\n",
    "                ious = [] #зануляем список средних по батчу\n",
    "\n",
    "                report_b = \"Batch #{}; Loss:{}; Mean IoU:{}\".format(b, avg_loss, mean_iou)\n",
    "\n",
    "                print(report_b)\n",
    "                b += 1\n",
    "                optimizer.step() #Оптимайзим\n",
    "                i = -1\n",
    "                optimizer.zero_grad() #Зануляемся\n",
    "            i += 1\n",
    "        if (avg_loss < best_loss): #Сохраняем модель если лосс улучшился\n",
    "            iou = np.array(epoch_iou).mean()\n",
    "            best_loss = avg_loss\n",
    "            report_loss = \"Epoch loss - {}. Epoch IoU - {}. Loss improved; Model Saved as {}\".format(avg_loss, iou, model_path + name_prefix + model_file)\n",
    "            torch.save(model,  model_path + name_prefix + model_file)\n",
    "            print(report_loss)\n",
    "        \n",
    "        else: #Или не сохраняем, если не\n",
    "            report_loss = \"Epoch last loss - {}. Not an improvement\".format(avg_loss)\n",
    "            print(report_loss)\n",
    "\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_shaper(img,shape:tuple):\n",
    "        if (shape[0] % 64 == 0) and (shape[1] % 64 == 0):\n",
    "            return img\n",
    "\n",
    "        indention_0 = 64 - shape[0] % 64\n",
    "        indention_1 = 64 - shape[1] % 64\n",
    "        \n",
    "        return img[indention_0 // 2:-(indention_0 - indention_0 // 2), indention_1 // 2:-(indention_1 - indention_1 // 2), :]\n",
    "    \n",
    "    \n",
    "def unet_deconstructor(dataset, tensor, dirr = '../data/stage1_train/'):\n",
    "    shapes = []\n",
    "    dec_images = []\n",
    "    \n",
    "    for ids in dataset.img_id:\n",
    "        img_dir = os.path.join(dirr, ids, 'images',ids + '.png')\n",
    "        shapes.append(cv2.imread(img_dir).shape)\n",
    "        \n",
    "    for i in range(len(dataset)):\n",
    "        dec_images.append(back_shaper(tensor[i].permute(1,2,0).numpy(),shapes[i]))\n",
    "    \n",
    "    return dec_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "544/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(512, 640, 3)\n",
      "(3, 640, 512)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(603, 1272, 3)\n",
      "(3, 1280, 608)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(512, 640, 3)\n",
      "(3, 640, 512)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(512, 640, 3)\n",
      "(3, 640, 512)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(512, 640, 3)\n",
      "(3, 640, 512)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(512, 640, 3)\n",
      "(3, 640, 512)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(512, 640, 3)\n",
      "(3, 640, 512)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(603, 1272, 3)\n",
      "(3, 1280, 608)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(512, 640, 3)\n",
      "(3, 640, 512)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(260, 347, 3)\n",
      "(3, 352, 288)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(512, 640, 3)\n",
      "(3, 640, 512)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(360, 360, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(260, 347, 3)\n",
      "(3, 352, 288)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(1040, 1388, 3)\n",
      "(3, 1408, 1056)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(603, 1272, 3)\n",
      "(3, 1280, 608)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(512, 640, 3)\n",
      "(3, 640, 512)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(260, 347, 3)\n",
      "(3, 352, 288)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(603, 1272, 3)\n",
      "(3, 1280, 608)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(512, 640, 3)\n",
      "(3, 640, 512)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(512, 640, 3)\n",
      "(3, 640, 512)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(603, 1272, 3)\n",
      "(3, 1280, 608)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(260, 347, 3)\n",
      "(3, 352, 288)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(603, 1272, 3)\n",
      "(3, 1280, 608)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(512, 640, 3)\n",
      "(3, 640, 512)\n",
      "(260, 347, 3)\n",
      "(3, 352, 288)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(512, 640, 3)\n",
      "(3, 640, 512)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(1024, 1024, 3)\n",
      "(3, 1024, 1024)\n",
      "(360, 360, 3)\n",
      "(3, 384, 384)\n",
      "(256, 320, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "for i in valid_dataset:\n",
    "    if i.shape[1]%32!=0 or i.shape[2]%32!=0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(360, 360, 3)\n",
      "(256, 320, 3)\n",
      "(512, 640, 3)\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(3, 384, 384)\n",
      "(520, 696, 3)\n",
      "(3, 320, 256)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(256, 320, 3)\n",
      "(520, 696, 3)\n",
      "(512, 640, 3)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(3, 320, 256)\n",
      "(520, 696, 3)\n",
      "(520, 696, 3)\n",
      "(3, 704, 544)\n",
      "(520, 696, 3)\n",
      "(360, 360, 3)\n",
      "(3, 704, 544)\n",
      "(256, 256, 3)\n",
      "(3, 256, 256)\n",
      "(520, 696, 3)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 11875) is killed by signal: Segmentation fault.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-9d93b5b99d1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cool_model.torch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader timed out after {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/stas/fastdata/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 11875) is killed by signal: Segmentation fault."
     ]
    }
   ],
   "source": [
    "model = torch.load(\"cool_model.torch\")\n",
    "model = model.eval()\n",
    "for data in validloader:\n",
    "    data = t.autograd.Variable(data, volatile=True).cuda()\n",
    "    o = model(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'o' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-aa0a18d9cd83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'o' is not defined"
     ]
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'o' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-cada8402a187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'o' is not defined"
     ]
    }
   ],
   "source": [
    "o = o - o.min()\n",
    "o = o / o.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'o' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6af78c45bab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#tra = 0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#low = flat < tra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'o' is not defined"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "#tra = 0.8\n",
    "flat = o[i][0].data.cpu().numpy()\n",
    "\n",
    "#low = flat < tra\n",
    "#high = flat >= tra\n",
    "\n",
    "#flat[low] = 0\n",
    "#flat[high] = 1\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(data[i].data.cpu().permute(1,2,0).numpy()*0.5+0.5)\n",
    "plt.subplot(122)\n",
    "plt.imshow(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = o.data.cpu().numpy()\n",
    "preds_test_t = (test_data > tra).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65, 1, 128, 128), (65, 1, 128, 128))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape,preds_test_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_upsampled = []\n",
    "for i in range(65):\n",
    "    preds_test_upsampled.append((resize(np.squeeze(preds_test_t[i][0]), \n",
    "                                       (256, 256),\n",
    "                                       mode='constant', preserve_range=True) > 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fee181e5be0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee183ad208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preds_test_upsampled[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(files):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['ImageId'] = sub.ImageId.apply(lambda x: str(x)[21:])\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.to_csv('sub-dsbowl2018-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0114f484a16c152baa2d82fdd43740880a762c93f436c8...</td>\n",
       "      <td>1 5 257 5 513 5 769 3 1025 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0114f484a16c152baa2d82fdd43740880a762c93f436c8...</td>\n",
       "      <td>64257 3 64513 3 64769 5 65025 5 65281 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0114f484a16c152baa2d82fdd43740880a762c93f436c8...</td>\n",
       "      <td>43818 16 44074 16 44328 20 44584 20 44838 24 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0114f484a16c152baa2d82fdd43740880a762c93f436c8...</td>\n",
       "      <td>49504 18 49760 18 50014 22 50270 22 50524 26 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0114f484a16c152baa2d82fdd43740880a762c93f436c8...</td>\n",
       "      <td>9098 10 9354 10 9606 16 9862 16 10116 20 10372...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ImageId  \\\n",
       "0  0114f484a16c152baa2d82fdd43740880a762c93f436c8...   \n",
       "1  0114f484a16c152baa2d82fdd43740880a762c93f436c8...   \n",
       "2  0114f484a16c152baa2d82fdd43740880a762c93f436c8...   \n",
       "3  0114f484a16c152baa2d82fdd43740880a762c93f436c8...   \n",
       "4  0114f484a16c152baa2d82fdd43740880a762c93f436c8...   \n",
       "\n",
       "                                       EncodedPixels  \n",
       "0                       1 5 257 5 513 5 769 3 1025 3  \n",
       "1            64257 3 64513 3 64769 5 65025 5 65281 5  \n",
       "2  43818 16 44074 16 44328 20 44584 20 44838 24 4...  \n",
       "3  49504 18 49760 18 50014 22 50270 22 50524 26 5...  \n",
       "4  9098 10 9354 10 9606 16 9862 16 10116 20 10372...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
